{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aad9456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/andressa.amaral/.local/lib/python3.8/site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from pandas) (1.23.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from pandas) (2022.6)\n",
      "Requirement already satisfied: six>=1.5 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in /home/andressa.amaral/.local/lib/python3.8/site-packages (0.12.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from seaborn) (3.6.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from seaborn) (1.23.4)\n",
      "Requirement already satisfied: pandas>=0.25 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from seaborn) (1.5.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.38.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.3.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from pandas>=0.25->seaborn) (2022.6)\n",
      "Requirement already satisfied: six>=1.5 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow-gpu in /home/andressa.amaral/.local/lib/python3.8/site-packages (2.11.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (22.10.26)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (3.19.6)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (1.14.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (4.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (0.27.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (0.4.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (3.7.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (2.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (14.0.6)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (1.23.4)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (2.11.0)\n",
      "Requirement already satisfied: packaging in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (21.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (1.50.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (2.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (2.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (65.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.30.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (2.2.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (2.14.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (0.6.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from packaging->tensorflow-gpu) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-gpu) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-gpu) (5.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (1.22)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (2018.1.18)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow-gpu) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-gpu) (3.10.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-gpu) (3.2.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: import-ipynb in /home/andressa.amaral/.local/lib/python3.8/site-packages (0.1.4)\n",
      "Requirement already satisfied: IPython in /home/andressa.amaral/.local/lib/python3.8/site-packages (from import-ipynb) (8.6.0)\n",
      "Requirement already satisfied: nbformat in /home/andressa.amaral/.local/lib/python3.8/site-packages (from import-ipynb) (5.7.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from IPython->import-ipynb) (2.13.0)\n",
      "Requirement already satisfied: decorator in /usr/lib/python3/dist-packages (from IPython->import-ipynb) (4.1.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from IPython->import-ipynb) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /home/andressa.amaral/.local/lib/python3.8/site-packages (from IPython->import-ipynb) (0.7.5)\n",
      "Requirement already satisfied: stack-data in /home/andressa.amaral/.local/lib/python3.8/site-packages (from IPython->import-ipynb) (0.6.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/andressa.amaral/.local/lib/python3.8/site-packages (from IPython->import-ipynb) (0.1.6)\n",
      "Requirement already satisfied: traitlets>=5 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from IPython->import-ipynb) (5.5.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>3.0.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from IPython->import-ipynb) (3.0.32)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from IPython->import-ipynb) (0.18.1)\n",
      "Requirement already satisfied: backcall in /home/andressa.amaral/.local/lib/python3.8/site-packages (from IPython->import-ipynb) (0.2.0)\n",
      "Requirement already satisfied: jupyter-core in /home/andressa.amaral/.local/lib/python3.8/site-packages (from nbformat->import-ipynb) (5.0.0)\n",
      "Requirement already satisfied: fastjsonschema in /home/andressa.amaral/.local/lib/python3.8/site-packages (from nbformat->import-ipynb) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from nbformat->import-ipynb) (4.17.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from jedi>=0.16->IPython->import-ipynb) (0.8.3)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (1.3.10)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.19.2)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (5.10.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from pexpect>4.3->IPython->import-ipynb) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/andressa.amaral/.local/lib/python3.8/site-packages (from prompt-toolkit<3.1.0,>3.0.1->IPython->import-ipynb) (0.2.5)\n",
      "Requirement already satisfied: platformdirs in /home/andressa.amaral/.local/lib/python3.8/site-packages (from jupyter-core->nbformat->import-ipynb) (2.5.4)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from stack-data->IPython->import-ipynb) (1.2.0)\n",
      "Requirement already satisfied: pure-eval in /home/andressa.amaral/.local/lib/python3.8/site-packages (from stack-data->IPython->import-ipynb) (0.2.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from stack-data->IPython->import-ipynb) (2.1.0)\n",
      "Requirement already satisfied: six in /home/andressa.amaral/.local/lib/python3.8/site-packages (from asttokens>=2.1.0->stack-data->IPython->import-ipynb) (1.16.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->import-ipynb) (3.10.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: cuda-python in /home/andressa.amaral/.local/lib/python3.8/site-packages (11.8.1)\n",
      "Requirement already satisfied: cython in /home/andressa.amaral/.local/lib/python3.8/site-packages (from cuda-python) (0.29.32)\n",
      "importing Jupyter notebook from AttackDetectionModel.ipynb\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas\n",
    "!pip3 install seaborn\n",
    "!pip3 install --upgrade tensorflow-gpu\n",
    "!pip3 install import-ipynb\n",
    "!pip3 install cuda-python\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import import_ipynb\n",
    "import AttackDetectionModel\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3358dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction = 0.333)\n",
    "sess = tf.compat.v1.Session(config = tf.compat.v1.ConfigProto(gpu_options = gpu_options))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb04791b",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79ff3684",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_features = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "392f5e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benign, df_attack = AttackDetectionModel.get_files_botiot(\"../../botiot\")\n",
    "\n",
    "df_benign = np.concatenate([df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, \n",
    "                            df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, \n",
    "                            df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, \n",
    "                            df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign,\n",
    "                            df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign])\n",
    "df_benign = shuffle(df_benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cb0bff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize with the min-max scaler\n",
    "scaler = MinMaxScaler()\n",
    "df_benign_norm = scaler.fit_transform(df_benign)\n",
    "df_attack_norm = scaler.fit_transform(df_attack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f03749",
   "metadata": {},
   "source": [
    "# Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3237bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "len_benign_train = int(0.7 * len(df_benign_norm))\n",
    "X_train = df_benign_norm[:len_benign_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a26ae71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "X_test_benign = df_benign_norm[len_benign_train:]\n",
    "X_test = np.concatenate([X_test_benign, df_attack_norm])\n",
    "\n",
    "Y_test = np.ones(len(X_test))\n",
    "Y_test[:len(X_test_benign)] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66ee87d",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59a8a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "original_dim = X_train.shape[1]\n",
    "input_shape = (original_dim,)\n",
    "intermediate_dim = int(original_dim / 2)\n",
    "latent_dim = int(original_dim / 3)\n",
    "\n",
    "# Initial values\n",
    "epochs = 5\n",
    "learning_rate = 0.0001\n",
    "batch_size = 10\n",
    "anomaly_threshold = 0.05\n",
    "\n",
    "# Dictionary\n",
    "dict_params = { 'learning_rate': learning_rate, 'batch_size': round(batch_size), 'epochs': round(epochs)}\n",
    "pbounds = { 'learning_rate': (0.000001, 0.001), 'batch_size': (10, 100), 'epochs': (50, 1000)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c66ed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KL Loss function\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    # Compute the average MSE error, then scale it up (sum on all axes)\n",
    "    \n",
    "    reconstruction_loss = K.sum(K.square(x - x_decoded_mean))\n",
    "    \n",
    "    # Compute the KL loss\n",
    "    \n",
    "    kl_loss = - 0.5 * K.sum(1 + z_var - K.square(z_mean) - K.square(K.exp(z_var)), axis=-1)\n",
    "    \n",
    "    # Return the average loss over all \n",
    "    \n",
    "    total_loss = K.mean(reconstruction_loss + kl_loss) # Total_loss = reconstruction_loss + kl_loss \n",
    "    return total_loss\n",
    "\n",
    "# (1) Reconstruction Loss - Forces the encoder to generate latent features that minimize the reconstruction error, or else is\n",
    "# penalized\n",
    "# (2) KL Loss - Forces the distribution generated by the encoder to be similar to the prior probability of the input vector, \n",
    "# pushing latent feature space to normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72309d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 35)]         0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 17)           612         ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 11)           198         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " z_var (Dense)                  (None, 11)           198         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " z (Lambda)                     (None, 11)           0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_var[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,008\n",
      "Trainable params: 1,008\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Encoder\n",
    "inputs, encoder, z_var, z_mean = AttackDetectionModel.vae_encoder(input_shape, \n",
    "                                                                  intermediate_dim, \n",
    "                                                                  latent_dim, \n",
    "                                                                  AttackDetectionModel.reparametrization)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9cf7f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " z_sampling (InputLayer)     [(None, 11)]              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 17)                204       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 35)                630       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 834\n",
      "Trainable params: 834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Decoder\n",
    "decoder = AttackDetectionModel.vae_decoder(intermediate_dim, latent_dim, original_dim)\n",
    "outputs = decoder(encoder(inputs))\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e5dee9",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee3147d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximize_training(X_train = X_train, \n",
    "                      X_test = X_test, \n",
    "                      Y_test = Y_test, \n",
    "                      inputs = inputs, \n",
    "                      outputs = outputs, \n",
    "                      vae_loss = vae_loss,\n",
    "                      learning_rate = learning_rate,\n",
    "                      batch_size = batch_size,\n",
    "                      epochs = epochs,\n",
    "                      anomaly_threshold = anomaly_threshold):    \n",
    "    \n",
    "    # Create model\n",
    "    opt_adam = optimizers.Adam(learning_rate = dict_params['learning_rate'], clipvalue = 0.5)\n",
    "    model = Model(inputs, outputs, name = 'vae_mlp')\n",
    "    model.compile(optimizer = opt_adam, loss = vae_loss)\n",
    "\n",
    "    # Train\n",
    "    history = model.fit(X_train, \n",
    "                        X_train, \n",
    "                        shuffle = True, \n",
    "                        verbose = 0,\n",
    "                        epochs = dict_params['epochs'], \n",
    "                        batch_size = dict_params['batch_size'])\n",
    "    \n",
    "    # Maximize the f1-score\n",
    "    X_pred_opt = model.predict(X_test)\n",
    "    error_vector_opt = AttackDetectionModel.get_error_term(X_pred_opt, X_test, _rmse = False)\n",
    "    Y_pred_opt = (error_vector_opt > anomaly_threshold)\n",
    "    f1 = f1_score(Y_test, Y_pred_opt)\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63435bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Apply Bayesian optimization to choose the best hyperparameters\\n\\nopt = BayesianOptimization(f = maximize_training,\\n                           pbounds = pbounds,\\n                           verbose = 2, \\n                           random_state = 1)\\n\\nopt_start = time.time()\\n\\nopt.maximize(init_points = 5, n_iter = 5)\\n\\nopt_end = time.time()\\nopt_time = opt_end - opt_start\\nprint(\"Optimization time:\", opt_time)\\n\\nlearning_rate = opt.max[\\'params\\'][\\'learning_rate\\']\\nepochs = round(opt.max[\\'params\\'][\\'epochs\\'])\\nbatch_size = round(opt.max[\\'params\\'][\\'batch_size\\'])\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Apply Bayesian optimization to choose the best hyperparameters\n",
    "\n",
    "opt = BayesianOptimization(f = maximize_training,\n",
    "                           pbounds = pbounds,\n",
    "                           verbose = 2, \n",
    "                           random_state = 1)\n",
    "\n",
    "opt_start = time.time()\n",
    "\n",
    "opt.maximize(init_points = 5, n_iter = 5)\n",
    "\n",
    "opt_end = time.time()\n",
    "opt_time = opt_end - opt_start\n",
    "print(\"Optimization time:\", opt_time)\n",
    "\n",
    "learning_rate = opt.max['params']['learning_rate']\n",
    "epochs = round(opt.max['params']['epochs'])\n",
    "batch_size = round(opt.max['params']['batch_size'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca82a597",
   "metadata": {},
   "source": [
    "# Predict Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "703c2623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training step with the best hyperparameters\n",
    "learning_rate = 0.0005007978127917845\n",
    "epochs = 550\n",
    "batch_size = 19\n",
    "opt_time = 1151.2620151042938\n",
    "anomaly_threshold = 0.043"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46d064a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Train on 15025 samples\n",
      "Epoch 1/550\n",
      "15025/15025 [==============================] - 2s 107us/sample - loss: 42.0174\n",
      "Epoch 2/550\n",
      "15025/15025 [==============================] - 1s 93us/sample - loss: 13.7064\n",
      "Epoch 3/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 11.4931\n",
      "Epoch 4/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 10.2848\n",
      "Epoch 5/550\n",
      "15025/15025 [==============================] - 1s 91us/sample - loss: 9.5255\n",
      "Epoch 6/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 9.0540\n",
      "Epoch 7/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 8.6942\n",
      "Epoch 8/550\n",
      "15025/15025 [==============================] - 1s 91us/sample - loss: 8.4716\n",
      "Epoch 9/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 8.2413\n",
      "Epoch 10/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 7.9871\n",
      "Epoch 11/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 7.8294\n",
      "Epoch 12/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 7.7070\n",
      "Epoch 13/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 7.5467\n",
      "Epoch 14/550\n",
      "15025/15025 [==============================] - 1s 91us/sample - loss: 7.3893\n",
      "Epoch 15/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 7.3062\n",
      "Epoch 16/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 7.2105\n",
      "Epoch 17/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 7.0818\n",
      "Epoch 18/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 6.9922\n",
      "Epoch 19/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 6.9073\n",
      "Epoch 20/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 6.8367\n",
      "Epoch 21/550\n",
      "15025/15025 [==============================] - 1s 91us/sample - loss: 6.8006\n",
      "Epoch 22/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 6.7579\n",
      "Epoch 23/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 6.6833\n",
      "Epoch 24/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 6.6399\n",
      "Epoch 25/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 6.5788\n",
      "Epoch 26/550\n",
      "15025/15025 [==============================] - 1s 91us/sample - loss: 6.5553\n",
      "Epoch 27/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 6.5372\n",
      "Epoch 28/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 6.4641\n",
      "Epoch 29/550\n",
      "15025/15025 [==============================] - 1s 93us/sample - loss: 6.4626\n",
      "Epoch 30/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 6.4459\n",
      "Epoch 31/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 6.3843\n",
      "Epoch 32/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 6.3552\n",
      "Epoch 33/550\n",
      "15025/15025 [==============================] - 1s 93us/sample - loss: 6.3340\n",
      "Epoch 34/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 6.2891\n",
      "Epoch 35/550\n",
      "15025/15025 [==============================] - 1s 93us/sample - loss: 6.2839\n",
      "Epoch 36/550\n",
      "15025/15025 [==============================] - 1s 93us/sample - loss: 6.2297\n",
      "Epoch 37/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 6.1966\n",
      "Epoch 38/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 6.1783\n",
      "Epoch 39/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 6.1327\n",
      "Epoch 40/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 6.1105\n",
      "Epoch 41/550\n",
      "15025/15025 [==============================] - 1s 93us/sample - loss: 6.0840\n",
      "Epoch 42/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 6.0624\n",
      "Epoch 43/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 6.0502\n",
      "Epoch 44/550\n",
      "15025/15025 [==============================] - 1s 91us/sample - loss: 6.0321\n",
      "Epoch 45/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 6.0338\n",
      "Epoch 46/550\n",
      "15025/15025 [==============================] - 1s 91us/sample - loss: 5.9934\n",
      "Epoch 47/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 5.9709\n",
      "Epoch 48/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 5.9714\n",
      "Epoch 49/550\n",
      "15025/15025 [==============================] - 1s 91us/sample - loss: 5.9445\n",
      "Epoch 50/550\n",
      "15025/15025 [==============================] - 1s 93us/sample - loss: 5.9421\n",
      "Epoch 51/550\n",
      "15025/15025 [==============================] - 2s 104us/sample - loss: 5.9107\n",
      "Epoch 52/550\n",
      "15025/15025 [==============================] - 2s 113us/sample - loss: 5.8998\n",
      "Epoch 53/550\n",
      "15025/15025 [==============================] - 2s 113us/sample - loss: 5.9310\n",
      "Epoch 54/550\n",
      "15025/15025 [==============================] - 2s 113us/sample - loss: 5.9397\n",
      "Epoch 55/550\n",
      "15025/15025 [==============================] - 2s 112us/sample - loss: 5.9021\n",
      "Epoch 56/550\n",
      "15025/15025 [==============================] - 2s 114us/sample - loss: 5.9062\n",
      "Epoch 57/550\n",
      "15025/15025 [==============================] - 2s 113us/sample - loss: 5.8830\n",
      "Epoch 58/550\n",
      "15025/15025 [==============================] - 2s 113us/sample - loss: 5.8265\n",
      "Epoch 59/550\n",
      "15025/15025 [==============================] - 2s 113us/sample - loss: 5.8510\n",
      "Epoch 60/550\n",
      "15025/15025 [==============================] - 2s 101us/sample - loss: 5.8660\n",
      "Epoch 61/550\n",
      "15025/15025 [==============================] - 2s 113us/sample - loss: 5.8756\n",
      "Epoch 62/550\n",
      "15025/15025 [==============================] - 2s 113us/sample - loss: 5.8508\n",
      "Epoch 63/550\n",
      "15025/15025 [==============================] - 2s 112us/sample - loss: 5.8957\n",
      "Epoch 64/550\n",
      "15025/15025 [==============================] - 2s 113us/sample - loss: 5.8442\n",
      "Epoch 65/550\n",
      "15025/15025 [==============================] - 2s 113us/sample - loss: 5.8575\n",
      "Epoch 66/550\n",
      "15025/15025 [==============================] - 2s 113us/sample - loss: 5.8312\n",
      "Epoch 67/550\n",
      "15025/15025 [==============================] - 2s 107us/sample - loss: 5.8791\n",
      "Epoch 68/550\n",
      "15025/15025 [==============================] - 2s 107us/sample - loss: 5.8641\n",
      "Epoch 69/550\n",
      "15025/15025 [==============================] - 2s 113us/sample - loss: 5.8330\n",
      "Epoch 70/550\n",
      "15025/15025 [==============================] - 2s 112us/sample - loss: 5.8665\n",
      "Epoch 71/550\n",
      "15025/15025 [==============================] - 2s 113us/sample - loss: 5.8488\n",
      "Epoch 72/550\n",
      "15025/15025 [==============================] - 2s 113us/sample - loss: 5.8016\n",
      "Epoch 73/550\n",
      "15025/15025 [==============================] - 2s 113us/sample - loss: 5.8318\n",
      "Epoch 74/550\n",
      "15025/15025 [==============================] - 2s 114us/sample - loss: 5.8063\n",
      "Epoch 75/550\n",
      "15025/15025 [==============================] - 2s 113us/sample - loss: 5.8648\n",
      "Epoch 76/550\n",
      "15025/15025 [==============================] - 2s 113us/sample - loss: 5.8347\n",
      "Epoch 77/550\n",
      "15025/15025 [==============================] - 2s 113us/sample - loss: 5.8551\n",
      "Epoch 78/550\n",
      "15025/15025 [==============================] - 2s 113us/sample - loss: 5.7760\n",
      "Epoch 79/550\n",
      "15025/15025 [==============================] - 2s 112us/sample - loss: 5.8303\n",
      "Epoch 80/550\n",
      "15025/15025 [==============================] - 2s 113us/sample - loss: 5.7597\n",
      "Epoch 81/550\n",
      "15025/15025 [==============================] - 2s 113us/sample - loss: 5.8004\n",
      "Epoch 82/550\n",
      "15025/15025 [==============================] - 2s 113us/sample - loss: 5.7647\n",
      "Epoch 83/550\n",
      "15025/15025 [==============================] - 2s 113us/sample - loss: 5.7755\n",
      "Epoch 84/550\n",
      "15025/15025 [==============================] - 2s 113us/sample - loss: 5.7771\n",
      "Epoch 85/550\n",
      "15025/15025 [==============================] - 2s 113us/sample - loss: 5.7769\n",
      "Epoch 86/550\n",
      "15025/15025 [==============================] - 2s 113us/sample - loss: 5.7566\n",
      "Epoch 87/550\n",
      "15025/15025 [==============================] - 2s 112us/sample - loss: 5.6993\n",
      "Epoch 88/550\n",
      "15025/15025 [==============================] - 2s 101us/sample - loss: 5.7670\n",
      "Epoch 89/550\n",
      "15025/15025 [==============================] - 1s 84us/sample - loss: 5.7694\n",
      "Epoch 90/550\n",
      "15025/15025 [==============================] - 1s 76us/sample - loss: 5.7509\n",
      "Epoch 91/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 5.7394\n",
      "Epoch 92/550\n",
      "15025/15025 [==============================] - 1s 90us/sample - loss: 5.7756\n",
      "Epoch 93/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.7179\n",
      "Epoch 94/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.7548\n",
      "Epoch 95/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.7366\n",
      "Epoch 96/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.6789\n",
      "Epoch 97/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.7294\n",
      "Epoch 98/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.6885\n",
      "Epoch 99/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.7472\n",
      "Epoch 100/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.7330\n",
      "Epoch 101/550\n",
      "15025/15025 [==============================] - 1s 90us/sample - loss: 5.6789\n",
      "Epoch 102/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.6804\n",
      "Epoch 103/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.7119\n",
      "Epoch 104/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.6825\n",
      "Epoch 105/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.6991\n",
      "Epoch 106/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.7369\n",
      "Epoch 107/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.7065\n",
      "Epoch 108/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.6849\n",
      "Epoch 109/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.6909\n",
      "Epoch 110/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.6770\n",
      "Epoch 111/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.7163\n",
      "Epoch 112/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.6503\n",
      "Epoch 113/550\n",
      "15025/15025 [==============================] - 1s 90us/sample - loss: 5.7601\n",
      "Epoch 114/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.7075\n",
      "Epoch 115/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.6987\n",
      "Epoch 116/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.6523\n",
      "Epoch 117/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.6633\n",
      "Epoch 118/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.6851\n",
      "Epoch 119/550\n",
      "15025/15025 [==============================] - 1s 90us/sample - loss: 5.6913\n",
      "Epoch 120/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.6863\n",
      "Epoch 121/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.6876\n",
      "Epoch 122/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.6898\n",
      "Epoch 123/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.6620\n",
      "Epoch 124/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 5.6840\n",
      "Epoch 125/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.6947\n",
      "Epoch 126/550\n",
      "15025/15025 [==============================] - 1s 87us/sample - loss: 5.6850\n",
      "Epoch 127/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 5.6803\n",
      "Epoch 128/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 5.6559\n",
      "Epoch 129/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 5.6741\n",
      "Epoch 130/550\n",
      "15025/15025 [==============================] - 1s 87us/sample - loss: 5.6511\n",
      "Epoch 131/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 5.5959\n",
      "Epoch 132/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 5.6597\n",
      "Epoch 133/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 5.6814\n",
      "Epoch 134/550\n",
      "15025/15025 [==============================] - 1s 87us/sample - loss: 5.6367\n",
      "Epoch 135/550\n",
      "15025/15025 [==============================] - 1s 86us/sample - loss: 5.6206\n",
      "Epoch 136/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.6844\n",
      "Epoch 137/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 5.6590\n",
      "Epoch 138/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.6935\n",
      "Epoch 139/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 5.6462\n",
      "Epoch 140/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.6233\n",
      "Epoch 141/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 5.6239\n",
      "Epoch 142/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.6388\n",
      "Epoch 143/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 5.6320\n",
      "Epoch 144/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.6276\n",
      "Epoch 145/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 5.6734\n",
      "Epoch 146/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.6638\n",
      "Epoch 147/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 5.6264\n",
      "Epoch 148/550\n",
      "15025/15025 [==============================] - 1s 93us/sample - loss: 5.7001\n",
      "Epoch 149/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.6431\n",
      "Epoch 150/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.6644\n",
      "Epoch 151/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.6353\n",
      "Epoch 152/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.7011\n",
      "Epoch 153/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.6285\n",
      "Epoch 154/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.6607\n",
      "Epoch 155/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.7084\n",
      "Epoch 156/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.7068\n",
      "Epoch 157/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.7263\n",
      "Epoch 158/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.6856\n",
      "Epoch 159/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.7125\n",
      "Epoch 160/550\n",
      "15025/15025 [==============================] - 1s 99us/sample - loss: 5.7411\n",
      "Epoch 161/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.6874\n",
      "Epoch 162/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.7046\n",
      "Epoch 163/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.7309\n",
      "Epoch 164/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.7039\n",
      "Epoch 165/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.7428\n",
      "Epoch 166/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.7224\n",
      "Epoch 167/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.7138\n",
      "Epoch 168/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.6739\n",
      "Epoch 169/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.6777\n",
      "Epoch 170/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.6647\n",
      "Epoch 171/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.7026\n",
      "Epoch 172/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.7061\n",
      "Epoch 173/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.6531\n",
      "Epoch 174/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.6767\n",
      "Epoch 175/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.6392\n",
      "Epoch 176/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.6723\n",
      "Epoch 177/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.6834\n",
      "Epoch 178/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.6808\n",
      "Epoch 179/550\n",
      "15025/15025 [==============================] - 1s 96us/sample - loss: 5.6893\n",
      "Epoch 180/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.6845\n",
      "Epoch 181/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.6715\n",
      "Epoch 182/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.6924\n",
      "Epoch 183/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.6350\n",
      "Epoch 184/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.6699\n",
      "Epoch 185/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.6851\n",
      "Epoch 186/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.6844\n",
      "Epoch 187/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.6893\n",
      "Epoch 188/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.7383\n",
      "Epoch 189/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.6682\n",
      "Epoch 190/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.7109\n",
      "Epoch 191/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.6327\n",
      "Epoch 192/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.6768\n",
      "Epoch 193/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.6370\n",
      "Epoch 194/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.6809\n",
      "Epoch 195/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.6697\n",
      "Epoch 196/550\n",
      "15025/15025 [==============================] - 1s 96us/sample - loss: 5.7214\n",
      "Epoch 197/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.6955\n",
      "Epoch 198/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.7100\n",
      "Epoch 199/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.7017\n",
      "Epoch 200/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.6841\n",
      "Epoch 201/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.6712\n",
      "Epoch 202/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.7213\n",
      "Epoch 203/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.6777\n",
      "Epoch 204/550\n",
      "15025/15025 [==============================] - 1s 99us/sample - loss: 5.7409\n",
      "Epoch 205/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.7517\n",
      "Epoch 206/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.7425\n",
      "Epoch 207/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.7016\n",
      "Epoch 208/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.7757\n",
      "Epoch 209/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.7511\n",
      "Epoch 210/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.7901\n",
      "Epoch 211/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.7925\n",
      "Epoch 212/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.8128\n",
      "Epoch 213/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.7822\n",
      "Epoch 214/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.7428\n",
      "Epoch 215/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.7898\n",
      "Epoch 216/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.8200\n",
      "Epoch 217/550\n",
      "15025/15025 [==============================] - 1s 96us/sample - loss: 5.7603\n",
      "Epoch 218/550\n",
      "15025/15025 [==============================] - 1s 96us/sample - loss: 5.8730\n",
      "Epoch 219/550\n",
      "15025/15025 [==============================] - 1s 96us/sample - loss: 5.8408\n",
      "Epoch 220/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.7978\n",
      "Epoch 221/550\n",
      "15025/15025 [==============================] - 1s 96us/sample - loss: 5.7650\n",
      "Epoch 222/550\n",
      "15025/15025 [==============================] - 1s 96us/sample - loss: 5.8689\n",
      "Epoch 223/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.8380\n",
      "Epoch 224/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.8800\n",
      "Epoch 225/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.9433\n",
      "Epoch 226/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.8489\n",
      "Epoch 227/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.9327\n",
      "Epoch 228/550\n",
      "15025/15025 [==============================] - 1s 99us/sample - loss: 5.8873\n",
      "Epoch 229/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.8352\n",
      "Epoch 230/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.8643\n",
      "Epoch 231/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.8581\n",
      "Epoch 232/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.8855\n",
      "Epoch 233/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.9631\n",
      "Epoch 234/550\n",
      "15025/15025 [==============================] - 1s 99us/sample - loss: 5.8821\n",
      "Epoch 235/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.9251\n",
      "Epoch 236/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.9448\n",
      "Epoch 237/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 5.9555\n",
      "Epoch 238/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.9837\n",
      "Epoch 239/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.9487\n",
      "Epoch 240/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.9533\n",
      "Epoch 241/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.9636\n",
      "Epoch 242/550\n",
      "15025/15025 [==============================] - 1s 96us/sample - loss: 5.9234\n",
      "Epoch 243/550\n",
      "15025/15025 [==============================] - 1s 95us/sample - loss: 6.0145\n",
      "Epoch 244/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.0177\n",
      "Epoch 245/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.0512\n",
      "Epoch 246/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.0419\n",
      "Epoch 247/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.0566\n",
      "Epoch 248/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 5.9908\n",
      "Epoch 249/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.0464\n",
      "Epoch 250/550\n",
      "15025/15025 [==============================] - 1s 96us/sample - loss: 6.0822\n",
      "Epoch 251/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.0389\n",
      "Epoch 252/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.1191\n",
      "Epoch 253/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.0554\n",
      "Epoch 254/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.1654\n",
      "Epoch 255/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.0909\n",
      "Epoch 256/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.1115\n",
      "Epoch 257/550\n",
      "15025/15025 [==============================] - 1s 96us/sample - loss: 6.1291\n",
      "Epoch 258/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.0889\n",
      "Epoch 259/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.1126\n",
      "Epoch 260/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.1655\n",
      "Epoch 261/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.1476\n",
      "Epoch 262/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.1584\n",
      "Epoch 263/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.1470\n",
      "Epoch 264/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.1828\n",
      "Epoch 265/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.2190\n",
      "Epoch 266/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.1243\n",
      "Epoch 267/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.1194\n",
      "Epoch 268/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.1958\n",
      "Epoch 269/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.1613\n",
      "Epoch 270/550\n",
      "15025/15025 [==============================] - 1s 96us/sample - loss: 6.2050\n",
      "Epoch 271/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.1799\n",
      "Epoch 272/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.1335\n",
      "Epoch 273/550\n",
      "15025/15025 [==============================] - 1s 96us/sample - loss: 6.1460\n",
      "Epoch 274/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.1526\n",
      "Epoch 275/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.1178\n",
      "Epoch 276/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.1366\n",
      "Epoch 277/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.1643\n",
      "Epoch 278/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.2377\n",
      "Epoch 279/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.2038\n",
      "Epoch 280/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.1769\n",
      "Epoch 281/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.1767\n",
      "Epoch 282/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.1623\n",
      "Epoch 283/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.1814\n",
      "Epoch 284/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.1840\n",
      "Epoch 285/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.1995\n",
      "Epoch 286/550\n",
      "15025/15025 [==============================] - 1s 96us/sample - loss: 6.2314\n",
      "Epoch 287/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.2401\n",
      "Epoch 288/550\n",
      "15025/15025 [==============================] - 1s 96us/sample - loss: 6.2060\n",
      "Epoch 289/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.2680\n",
      "Epoch 290/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.2836\n",
      "Epoch 291/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.2690\n",
      "Epoch 292/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.3452\n",
      "Epoch 293/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.2923\n",
      "Epoch 294/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.3187\n",
      "Epoch 295/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.3175\n",
      "Epoch 296/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.3277\n",
      "Epoch 297/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.3685\n",
      "Epoch 298/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.3839\n",
      "Epoch 299/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.3233\n",
      "Epoch 300/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.3298\n",
      "Epoch 301/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.3416\n",
      "Epoch 302/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.4727\n",
      "Epoch 303/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.3458\n",
      "Epoch 304/550\n",
      "15025/15025 [==============================] - 1s 99us/sample - loss: 6.4134\n",
      "Epoch 305/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.4022\n",
      "Epoch 306/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.4239\n",
      "Epoch 307/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.4158\n",
      "Epoch 308/550\n",
      "15025/15025 [==============================] - 1s 99us/sample - loss: 6.4215\n",
      "Epoch 309/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.3983\n",
      "Epoch 310/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.4180\n",
      "Epoch 311/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.4869\n",
      "Epoch 312/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.4358\n",
      "Epoch 313/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.4916\n",
      "Epoch 314/550\n",
      "15025/15025 [==============================] - 1s 96us/sample - loss: 6.5214\n",
      "Epoch 315/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.5792\n",
      "Epoch 316/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.4996\n",
      "Epoch 317/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.5165\n",
      "Epoch 318/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.5644\n",
      "Epoch 319/550\n",
      "15025/15025 [==============================] - 1s 95us/sample - loss: 6.5649\n",
      "Epoch 320/550\n",
      "15025/15025 [==============================] - 1s 95us/sample - loss: 6.5878\n",
      "Epoch 321/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.5972\n",
      "Epoch 322/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.5464\n",
      "Epoch 323/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.5330\n",
      "Epoch 324/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.5629\n",
      "Epoch 325/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.5284\n",
      "Epoch 326/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.5285\n",
      "Epoch 327/550\n",
      "15025/15025 [==============================] - 1s 96us/sample - loss: 6.5094\n",
      "Epoch 328/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.5699\n",
      "Epoch 329/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.5092\n",
      "Epoch 330/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.5312\n",
      "Epoch 331/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.5867\n",
      "Epoch 332/550\n",
      "15025/15025 [==============================] - 1s 98us/sample - loss: 6.5082\n",
      "Epoch 333/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.5492\n",
      "Epoch 334/550\n",
      "15025/15025 [==============================] - 1s 97us/sample - loss: 6.4831\n",
      "Epoch 335/550\n",
      "15025/15025 [==============================] - 1s 96us/sample - loss: 6.4835\n",
      "Epoch 336/550\n",
      "15025/15025 [==============================] - 1s 93us/sample - loss: 6.4694\n",
      "Epoch 337/550\n",
      "15025/15025 [==============================] - 1s 93us/sample - loss: 6.4289\n",
      "Epoch 338/550\n",
      "15025/15025 [==============================] - 1s 93us/sample - loss: 6.4980\n",
      "Epoch 339/550\n",
      "15025/15025 [==============================] - 1s 93us/sample - loss: 6.4369\n",
      "Epoch 340/550\n",
      "15025/15025 [==============================] - 1s 93us/sample - loss: 6.4826\n",
      "Epoch 341/550\n",
      "15025/15025 [==============================] - 1s 93us/sample - loss: 6.4353\n",
      "Epoch 342/550\n",
      "15025/15025 [==============================] - 1s 93us/sample - loss: 6.4456\n",
      "Epoch 343/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 6.4212\n",
      "Epoch 344/550\n",
      "15025/15025 [==============================] - 1s 93us/sample - loss: 6.4668\n",
      "Epoch 345/550\n",
      "15025/15025 [==============================] - 1s 93us/sample - loss: 6.4734\n",
      "Epoch 346/550\n",
      "15025/15025 [==============================] - 1s 93us/sample - loss: 6.5235\n",
      "Epoch 347/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 6.5079\n",
      "Epoch 348/550\n",
      "15025/15025 [==============================] - 1s 91us/sample - loss: 6.4988\n",
      "Epoch 349/550\n",
      "15025/15025 [==============================] - 1s 90us/sample - loss: 6.5050\n",
      "Epoch 350/550\n",
      "15025/15025 [==============================] - 1s 91us/sample - loss: 6.5284\n",
      "Epoch 351/550\n",
      "15025/15025 [==============================] - 1s 93us/sample - loss: 6.4653\n",
      "Epoch 352/550\n",
      "15025/15025 [==============================] - 1s 91us/sample - loss: 6.4535\n",
      "Epoch 353/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 6.4363\n",
      "Epoch 354/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 6.5265\n",
      "Epoch 355/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 6.5244\n",
      "Epoch 356/550\n",
      "15025/15025 [==============================] - 1s 93us/sample - loss: 6.4402\n",
      "Epoch 357/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 6.4658\n",
      "Epoch 358/550\n",
      "15025/15025 [==============================] - 1s 93us/sample - loss: 6.4687\n",
      "Epoch 359/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 6.4834\n",
      "Epoch 360/550\n",
      "15025/15025 [==============================] - 1s 92us/sample - loss: 6.5352\n",
      "Epoch 361/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15025/15025 [==============================] - 1s 91us/sample - loss: 6.4842\n",
      "Epoch 362/550\n",
      "15025/15025 [==============================] - 1s 81us/sample - loss: 6.4648\n",
      "Epoch 363/550\n",
      "15025/15025 [==============================] - 1s 85us/sample - loss: 6.4714\n",
      "Epoch 364/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.5031\n",
      "Epoch 365/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.5207\n",
      "Epoch 366/550\n",
      "15025/15025 [==============================] - 1s 87us/sample - loss: 6.5182\n",
      "Epoch 367/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.5198\n",
      "Epoch 368/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.5409\n",
      "Epoch 369/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.5592\n",
      "Epoch 370/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.5821\n",
      "Epoch 371/550\n",
      "15025/15025 [==============================] - 1s 87us/sample - loss: 6.4767\n",
      "Epoch 372/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.5943\n",
      "Epoch 373/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.5487\n",
      "Epoch 374/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.5516\n",
      "Epoch 375/550\n",
      "15025/15025 [==============================] - 1s 87us/sample - loss: 6.5643\n",
      "Epoch 376/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.5476\n",
      "Epoch 377/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.5762\n",
      "Epoch 378/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.5540\n",
      "Epoch 379/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.5742\n",
      "Epoch 380/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.6517\n",
      "Epoch 381/550\n",
      "15025/15025 [==============================] - 1s 87us/sample - loss: 6.5620\n",
      "Epoch 382/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.6502\n",
      "Epoch 383/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.6544\n",
      "Epoch 384/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.6661\n",
      "Epoch 385/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.6471\n",
      "Epoch 386/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.5922\n",
      "Epoch 387/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.6337\n",
      "Epoch 388/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.6354\n",
      "Epoch 389/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.7148\n",
      "Epoch 390/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.6250\n",
      "Epoch 391/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.6520\n",
      "Epoch 392/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.6694\n",
      "Epoch 393/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.6600\n",
      "Epoch 394/550\n",
      "15025/15025 [==============================] - 1s 87us/sample - loss: 6.6257\n",
      "Epoch 395/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.6231\n",
      "Epoch 396/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.6561\n",
      "Epoch 397/550\n",
      "15025/15025 [==============================] - 1s 87us/sample - loss: 6.6434\n",
      "Epoch 398/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.6686\n",
      "Epoch 399/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.6888\n",
      "Epoch 400/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.6758\n",
      "Epoch 401/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.6859\n",
      "Epoch 402/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.6211\n",
      "Epoch 403/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.6255\n",
      "Epoch 404/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.5862\n",
      "Epoch 405/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.5937\n",
      "Epoch 406/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.6054\n",
      "Epoch 407/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.6981\n",
      "Epoch 408/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.6423\n",
      "Epoch 409/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.6216\n",
      "Epoch 410/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.5933\n",
      "Epoch 411/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.6536\n",
      "Epoch 412/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.6013\n",
      "Epoch 413/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.6441\n",
      "Epoch 414/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.6125\n",
      "Epoch 415/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.6866\n",
      "Epoch 416/550\n",
      "15025/15025 [==============================] - 1s 87us/sample - loss: 6.6023\n",
      "Epoch 417/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.6136\n",
      "Epoch 418/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.6377\n",
      "Epoch 419/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.6080\n",
      "Epoch 420/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.6355\n",
      "Epoch 421/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.6428\n",
      "Epoch 422/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.6326\n",
      "Epoch 423/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.5832\n",
      "Epoch 424/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.6411\n",
      "Epoch 425/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.5749\n",
      "Epoch 426/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.6897\n",
      "Epoch 427/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.6185\n",
      "Epoch 428/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.6326\n",
      "Epoch 429/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.5986\n",
      "Epoch 430/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.6015\n",
      "Epoch 431/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.5936\n",
      "Epoch 432/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.6276\n",
      "Epoch 433/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.6217\n",
      "Epoch 434/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.5750\n",
      "Epoch 435/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.5669\n",
      "Epoch 436/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.6364\n",
      "Epoch 437/550\n",
      "15025/15025 [==============================] - 1s 90us/sample - loss: 6.6243\n",
      "Epoch 438/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.6170\n",
      "Epoch 439/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.6111\n",
      "Epoch 440/550\n",
      "15025/15025 [==============================] - 1s 90us/sample - loss: 6.5270\n",
      "Epoch 441/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.5383\n",
      "Epoch 442/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.5891\n",
      "Epoch 443/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.5152\n",
      "Epoch 444/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.5359\n",
      "Epoch 445/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.5151\n",
      "Epoch 446/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.4947\n",
      "Epoch 447/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.5201\n",
      "Epoch 448/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.4560\n",
      "Epoch 449/550\n",
      "15025/15025 [==============================] - 1s 90us/sample - loss: 6.4621\n",
      "Epoch 450/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.4764\n",
      "Epoch 451/550\n",
      "15025/15025 [==============================] - 1s 90us/sample - loss: 6.4699\n",
      "Epoch 452/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3993\n",
      "Epoch 453/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.4717\n",
      "Epoch 454/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.4591\n",
      "Epoch 455/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.4278\n",
      "Epoch 456/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.4361\n",
      "Epoch 457/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.4176\n",
      "Epoch 458/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3994\n",
      "Epoch 459/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3779\n",
      "Epoch 460/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.4665\n",
      "Epoch 461/550\n",
      "15025/15025 [==============================] - 1s 90us/sample - loss: 6.3748\n",
      "Epoch 462/550\n",
      "15025/15025 [==============================] - 1s 90us/sample - loss: 6.3777\n",
      "Epoch 463/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.4519\n",
      "Epoch 464/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3896\n",
      "Epoch 465/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3546\n",
      "Epoch 466/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3329\n",
      "Epoch 467/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3859\n",
      "Epoch 468/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.4258\n",
      "Epoch 469/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3445\n",
      "Epoch 470/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3802\n",
      "Epoch 471/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3376\n",
      "Epoch 472/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3248\n",
      "Epoch 473/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3731\n",
      "Epoch 474/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3590\n",
      "Epoch 475/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3060\n",
      "Epoch 476/550\n",
      "15025/15025 [==============================] - 1s 90us/sample - loss: 6.3314\n",
      "Epoch 477/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3707\n",
      "Epoch 478/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.4220\n",
      "Epoch 479/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3297\n",
      "Epoch 480/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3021\n",
      "Epoch 481/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3695\n",
      "Epoch 482/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.3382\n",
      "Epoch 483/550\n",
      "15025/15025 [==============================] - 1s 90us/sample - loss: 6.3323\n",
      "Epoch 484/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3787\n",
      "Epoch 485/550\n",
      "15025/15025 [==============================] - 1s 90us/sample - loss: 6.3298\n",
      "Epoch 486/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3176\n",
      "Epoch 487/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3602\n",
      "Epoch 488/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.4447\n",
      "Epoch 489/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3975\n",
      "Epoch 490/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.4216\n",
      "Epoch 491/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.4302\n",
      "Epoch 492/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.4288\n",
      "Epoch 493/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.4402\n",
      "Epoch 494/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3702\n",
      "Epoch 495/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3898\n",
      "Epoch 496/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3559\n",
      "Epoch 497/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3931\n",
      "Epoch 498/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3968\n",
      "Epoch 499/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3886\n",
      "Epoch 500/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3573\n",
      "Epoch 501/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3799\n",
      "Epoch 502/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.3890\n",
      "Epoch 503/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.4197\n",
      "Epoch 504/550\n",
      "15025/15025 [==============================] - 1s 87us/sample - loss: 6.4088\n",
      "Epoch 505/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.4306\n",
      "Epoch 506/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3904\n",
      "Epoch 507/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.3987\n",
      "Epoch 508/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.4371\n",
      "Epoch 509/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.4128\n",
      "Epoch 510/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.4802\n",
      "Epoch 511/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.4364\n",
      "Epoch 512/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.4235\n",
      "Epoch 513/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.4883\n",
      "Epoch 514/550\n",
      "15025/15025 [==============================] - 1s 89us/sample - loss: 6.4924\n",
      "Epoch 515/550\n",
      "15025/15025 [==============================] - 1s 90us/sample - loss: 6.5134\n",
      "Epoch 516/550\n",
      "15025/15025 [==============================] - 1s 90us/sample - loss: 6.4415\n",
      "Epoch 517/550\n",
      "15025/15025 [==============================] - 1s 90us/sample - loss: 6.5254\n",
      "Epoch 518/550\n",
      "15025/15025 [==============================] - 1s 91us/sample - loss: 6.4935\n",
      "Epoch 519/550\n",
      "15025/15025 [==============================] - 2s 111us/sample - loss: 6.5186\n",
      "Epoch 520/550\n",
      "15025/15025 [==============================] - 2s 111us/sample - loss: 6.5357\n",
      "Epoch 521/550\n",
      "15025/15025 [==============================] - 2s 111us/sample - loss: 6.5410\n",
      "Epoch 522/550\n",
      "15025/15025 [==============================] - 2s 111us/sample - loss: 6.4862\n",
      "Epoch 523/550\n",
      "15025/15025 [==============================] - 2s 110us/sample - loss: 6.5248\n",
      "Epoch 524/550\n",
      "15025/15025 [==============================] - 2s 110us/sample - loss: 6.5104\n",
      "Epoch 525/550\n",
      "15025/15025 [==============================] - 2s 111us/sample - loss: 6.5289\n",
      "Epoch 526/550\n",
      "15025/15025 [==============================] - 2s 110us/sample - loss: 6.5416\n",
      "Epoch 527/550\n",
      "15025/15025 [==============================] - 2s 110us/sample - loss: 6.5407\n",
      "Epoch 528/550\n",
      "15025/15025 [==============================] - 2s 110us/sample - loss: 6.4807\n",
      "Epoch 529/550\n",
      "15025/15025 [==============================] - 2s 110us/sample - loss: 6.5914\n",
      "Epoch 530/550\n",
      "15025/15025 [==============================] - 2s 109us/sample - loss: 6.4780\n",
      "Epoch 531/550\n",
      "15025/15025 [==============================] - 2s 110us/sample - loss: 6.5504\n",
      "Epoch 532/550\n",
      "15025/15025 [==============================] - 2s 110us/sample - loss: 6.5491\n",
      "Epoch 533/550\n",
      "15025/15025 [==============================] - 2s 109us/sample - loss: 6.5288\n",
      "Epoch 534/550\n",
      "15025/15025 [==============================] - 2s 111us/sample - loss: 6.5780\n",
      "Epoch 535/550\n",
      "15025/15025 [==============================] - 2s 110us/sample - loss: 6.5839\n",
      "Epoch 536/550\n",
      "15025/15025 [==============================] - 2s 110us/sample - loss: 6.6990\n",
      "Epoch 537/550\n",
      "15025/15025 [==============================] - 2s 110us/sample - loss: 6.6343\n",
      "Epoch 538/550\n",
      "15025/15025 [==============================] - 2s 110us/sample - loss: 6.5229\n",
      "Epoch 539/550\n",
      "15025/15025 [==============================] - 2s 110us/sample - loss: 6.5424\n",
      "Epoch 540/550\n",
      "15025/15025 [==============================] - 2s 111us/sample - loss: 6.5242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 541/550\n",
      "15025/15025 [==============================] - 2s 110us/sample - loss: 6.5382\n",
      "Epoch 542/550\n",
      "15025/15025 [==============================] - 2s 111us/sample - loss: 6.5360\n",
      "Epoch 543/550\n",
      "15025/15025 [==============================] - 2s 110us/sample - loss: 6.6256\n",
      "Epoch 544/550\n",
      "15025/15025 [==============================] - 2s 111us/sample - loss: 6.5685\n",
      "Epoch 545/550\n",
      "15025/15025 [==============================] - 2s 110us/sample - loss: 6.5552\n",
      "Epoch 546/550\n",
      "15025/15025 [==============================] - 2s 111us/sample - loss: 6.6058\n",
      "Epoch 547/550\n",
      "15025/15025 [==============================] - 2s 111us/sample - loss: 6.6472\n",
      "Epoch 548/550\n",
      "15025/15025 [==============================] - 2s 111us/sample - loss: 6.5778\n",
      "Epoch 549/550\n",
      "15025/15025 [==============================] - 2s 110us/sample - loss: 6.5839\n",
      "Epoch 550/550\n",
      "15025/15025 [==============================] - 2s 111us/sample - loss: 6.5951\n",
      "Training time: 785.3959271907806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andressa.amaral/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing time: 100.97874331474304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    print(\"Iteration \" + str(i))\n",
    "    \n",
    "    # Train\n",
    "    vae_model, train_time = AttackDetectionModel.train(X_train, inputs, outputs, vae_loss, learning_rate, epochs, batch_size)\n",
    "    \n",
    "    # Set the optimized anomaly threshold\n",
    "    #anomaly_threshold = AttackDetectionModel.get_anomaly_threshold(X_train, vae_model)\n",
    "    \n",
    "    # Test\n",
    "    X_pred, test_time = AttackDetectionModel.test(X_test, vae_model)\n",
    "    Y_test, Y_pred = AttackDetectionModel.get_prediction(Y_test, X_pred, X_test, anomaly_threshold, vae_model)\n",
    "    \n",
    "    # Metrics\n",
    "    acc, f1, pre, rec = AttackDetectionModel.get_scores(Y_test, Y_pred)\n",
    "    \n",
    "    # Print results\n",
    "    AttackDetectionModel.print_results(number_features,\n",
    "                                       learning_rate,\n",
    "                                       epochs,\n",
    "                                       batch_size,\n",
    "                                       anomaly_threshold,\n",
    "                                       X_train,\n",
    "                                       X_test,\n",
    "                                       opt_time,\n",
    "                                       train_time,\n",
    "                                       test_time,\n",
    "                                       acc,\n",
    "                                       f1,\n",
    "                                       pre,\n",
    "                                       rec,\n",
    "                                       Y_test,\n",
    "                                       Y_pred,\n",
    "                                       \"Results/botiot.txt\")\n",
    "    \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c84108b",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c5c3ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andressa.amaral/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    }
   ],
   "source": [
    "# Examinig the latent space generated by the encoder\n",
    "X_encoded = encoder.predict(X_test)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_analysis = pca.fit_transform(X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4518c113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "sns.scatterplot(x = X_analysis[:, 0], y = X_analysis[:, 1], s = 20, hue = Y_pred)\n",
    "plt.grid()\n",
    "plt.savefig(\"Results/PCA/Botiot\")\n",
    "plt.show()\n",
    "\n",
    "# Orange ones are anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "360d1451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8, 8))\n",
    "sns.scatterplot(x = X_analysis[:, 0], y = X_analysis[:, 1], s = 20, hue = Y_test)\n",
    "plt.grid()\n",
    "plt.savefig(\"Results/PCA Groundtruth/Botiot\")\n",
    "plt.show()\n",
    "\n",
    "# Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9b7783c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcEAAAHLCAYAAACwICOOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA7BklEQVR4nO3deXgNZ//H8c/JvkgixE5EbeGhsSuqCGovtZSWCrpq+VV11Q1dtVptla6PfXlsrZaqaGtvUa3Y9xK7kEhkl0Qyvz/SnIrsyYlg3q/rOpdzZuae+c65cs7HzNz3HIthGIYAADAhu5IuAACAkkIIAgBMixAEAJgWIQgAMC1CEABgWoQgAMC0CEEAgGkRggAA0yIEAQCmRQgCAEyLEITNTZ8+XX5+fnJxcVHLli21ffv2ki4JuCE2bdqkXr16qXLlyrJYLPr+++9LuiTkgRCETS1evFhjx47V+PHjFRISooCAAHXp0kUXL14s6dKAYhcfH6+AgABNnz69pEtBPlm4gTZsqWXLlmrevLmmTZsmSUpLS1O1atU0evRovfzyyyVcHXDjWCwWLV++XH369CnpUpALjgRhM8nJydqxY4c6depknWZnZ6dOnTpp69atJVgZAGSPEITNREREKDU1VRUqVMg0vUKFCgoLCyuhqgAgZ4QgAMC0CEHYjI+Pj+zt7XXhwoVM0y9cuKCKFSuWUFUAkDNCEDbj5OSkpk2bau3atdZpaWlpWrt2rVq1alWClQFA9hxKugDcXsaOHaugoCA1a9ZMLVq00CeffKL4+HgNHz68pEsDil1cXJz+/vtv6+vQ0FDt2rVLZcqUka+vbwlWhpwwRAI2N23aNE2ePFlhYWFq1KiRpk6dqpYtW5Z0WUCx27Bhgzp06JBlelBQkGbPnn3jC0KeCEEAgGlxTRAAYFqEIADAtAhBAIBpEYIAANMiBAEApkUIAgBMixAEAJgWIQibS0pK0oQJE5SUlFTSpQAlgs/ArYPB8rC5mJgYeXl5KTo6Wp6eniVdDnDD8Rm4dXAkCAAwLUIQAGBat+WvSKSlpencuXPy8PCQxWIp6XJMJyYmJtO/gNnwGShZhmEoNjZWlStXlp1d7sd6t+U1wTNnzqhatWolXQYAoASdPn1aVatWzXWZ2/JI0MPDQ5J04uRpLkoDgMnExMTIr3o1axbk5rYMwYxToJ6enoQgAJhUfi6H0TEGAGBahCAAwLQIQQCAaRGCAADTIgQBAKZFCAIATIsQBACYFiEIADAtQhAAYFqEIADAtAhBAIBpEYIAANMiBAEApkUIAgBMixAEAJgWIQgAMC1CEABgWoQgAMC0CEEAgGkRggAA0yIEAQCmRQgCAEyLEAQAmBYhCAAwLUIQAGBahCAAwLQIQQCAaRGCAADTIgQBAKZFCAIATIsQBACYFiEIADAtQhAAYFqEIADAtAhBAIBpEYIAANMiBAEApkUIAgBMixAEAJgWIQgAMC1CEABgWoQgAMC0CEEAgGkRggAA0yIEAQCmRQgCAEyLEAQAmBYhCAAwLUIQAGBahCAAwLQIQQCAaRGCAADTIgQBAKZFCAIATIsQBACYFiEIADAtQhAAYFqEIADAtAhBAIBpEYIAANMiBAEApkUIAgBMixAEAJgWIQgAMC1CEABgWoQgAMC0CEEAgGkRggAA0yIEAQCmRQgCAEyLEAQAmBYhCAAwLUIQAGBahCAAwLQIQQCAaRGCAADTIgQBAKZFCAIATIsQBACYFiEIADAtQhAAYFqEIADAtAhBk5gze7Yc7C15Pn799dcsbUcMH5avtlevXs2zjg0bNmj4sCDVrnWHPEq5yaestxo2qK8Rw4cpODg42zaHDh3SrJkzNXrU02rTppU8SrlZtwnY0i+//KJBAx/QHTWqy93NRaXcXVW71h16eMhgbdy4Mds2+flsZDw6duyQ47ZXrlih3vf1UpXKFeXq4qSqVSrp/j69tXr16uLaXUhyKOkCcGPZ2dmpXLlyOc53dnbOcZ6Li4u8vLxynG+x5BxKycnJevyxRzV//jzrNC8vLyUkJOjgwYM6ePCgLl++rK5du2Zp+9RTT2pTDl9AgC0YhqGnnxqpr7/+yjrN1dVVkhQaGqrQ0FD9738L9cyYZ/XRR1Myta1QoUKu605JSVFkZKQkqVmz5lnmp6amaviwIC1cuEBS+ueodOnSCg8P18qVK7Ry5QqNGjVan3w6tUj7iOxxJGgy1apV09lzYTk+2rZtm2PbBx4YmGtbe3v7bNsZhqGBDwzQ/PnzVK5cOX3xxVcKj4jUpcjLik+4otNnzmnOnHnqEBiYbXsHBwfVr19fgwcP0YcfTdGYZ8fa5L0AMsyZPdsagP369dfBQ0cUG5eg2LgE7T9wSPfd11uS9OknH+v75csztc3tM3H2XJheHveKddkRIx7Jsu3XX3/NGoD/93/PKOxCuMIjIhUZFa0PJn8oBwcHTZv2mT77jBAsDhwJoth9/dVXWrlyhby9vbX5ty2qVauWdZ7FYlGlSpU0eMiQHNuvXr0mU8DOmT27OMuFCc2bP1eSVKtWLS1Y+D85OPz71Vi3bl0tXrJU/6nvr+PHj2vp0iXqc//9+V73rJkzJElt7r5bdevWzTQvIiJCn37ysSSpd+8+mvLxJ9Z57u7uGjv2OYWHh2vyB+9r4oTxCgoaJk9Pz8LuJrLBkSCKVWpqqt577x1J0utvjM8UgPmV0xEmYCth589Lku68MyBTAGZwdHRUQEAjSVJcXFy+17tlyxYdPHhQkvTIiEezzF+3dq2SkpIkSc89/0K263jhhRclSZcvX9YP33+f720jfwhBFKt169bpzJkzkqTBg3M+2gNKUo0ad0iS9uzZnW0Hr5SUFO3evUuS1LRZs3yvN+Mo0MvLS/0HDMgy/+Spk9bn9evXz3YdZcqUUfny5SVJv/zyc763jfy5qUNw+vTp8vPzk4uLi1q2bKnt27eXdEm3vPDwcLVo3lRenqWsPd+GPjxEGzZsyLPtunVrVc+/jtzdXORd2lONAhpq7LNjdPTo0Rzb/P77b5IkPz8/lS1bVnPnzNHdd7eWd2lPeXmWUqOAhnrllXEKDw+31S4CBfbEkyMlSX///bcGP/Sg/v77b+u8w4cPa9DAB3T8+HHVrFlTY8Y8m691xsXFaenSJZKkQYMelJubW67Lp6am5jlv3769+do28u+mDcHFixdr7NixGj9+vEJCQhQQEKAuXbro4sWLJV3aLS0hIUEhISFycnJSWlqaQkNDtXDhAnXq2EGPPjIi12EOZ86c0fHjx+Xm5qaEhATt27dPU6d+qoA7G+jLL77Its3RI0ckST4+PnrowUEaMWKYtm3dKnt7e6WkpGjfvn364P1JahTQUDt27CiWfQby0qtXL3005WM5OTnp22+Xyb9ubXmUcpNHKTf9p76/Nm7coCefHKmt27bn+5rc4kWLrKdORzyS9VSoJPlV97M+37dvX7bLhIWF6dKlS5Kkc+fOFWCvkB83bQhOmTJFjz32mIYPH6769evryy+/lJubm2bOnFnSpd2SKlWurNffGK+QnbsVn3BF4RGRio1L0KbNv6tjx06SpNmzZ+m5sVn/l9u4SRNN/Wyajh0/oYTEJIVHRCrqcoyWLv1WNWvWVHJyskaNekrfffttlrZRUVGSpJCQEC1ZslgPPDBQx0NPKuJSlKJj4rRo0RJ5e3vrwoUL6nt/b8XGxhbvGwHk4Jlnxmjpsu+spx4TExOVmJgoKX2IT1xcnKKjo/O9vhkz/ytJCggIUNOmTbNdpkNgoHVY0nvvvpPtMtdOj4mJyff2kU/GTSgpKcmwt7c3li9fnmn60KFDjfvuuy/P9tHR0YYkIzIq2riaavDI45Gckmrcd19vQ5JhZ2dnHDx0JN9tL1yMMGrUqGFIMqpXr26kXE3LNL9Tp86GJEOS0bhxYyM5JTXLOpYsWWZd5sOPpuS5zRkzZlmXL+n3jsft8YiJjTcGDHjAkGQ0a9bMWB38sxF2IdwIuxBurA7+2WjWrJkhyfDx8TFCdu7Oc3279+yz/o1+OvWzXJd97vkXrMs+9NBgY9/+g0bilWTjeOhJ44UXXzIsFovh6OhoSDJcXFxK/L26FR6RUekZEB0dnWde3JRHghEREUpNTc0yCLVChQoKCwvLsnxSUpJiYmIyPZB/dnZ2+mDyh5KktLQ0/fjjyny3LVu2rF5+OX0c1MmTJ7Vz585M8z08PKzPn332OdnZZf2T69uvn7XX6C8/c+EfN95LL76gpUuXqG7dutqwcbM6d+4sHx8f+fj4qHPnzlq/YZPq1KmjiIgIjR79dJ7rmzEj/SjQxcUlzw5h77zzrgYOHCRJWrhwgRr8p55cXZx0R43qmvzB+2rRsqV1fKG3t3cR9xTXuylDsKDee+89eXl5WR/VqlUr6ZJuObVq1ZKPj48kKfT48QK1vatVK+vz69tWqVLF+ty/Xr0c1+Hvnz7v1DW95YAbITY2Vt9887UkaeRTT8vFxSXLMq6urnrq6VGSpN9/+y3XvgnJyclauGC+JKlv334qXbp0rtt3cHDQgoX/04qVq/TAAwPl7++v6tWr6+62bfXJp1O1YcMmJSQkSJJq16lTmF1ELm7KwfI+Pj6yt7fXhQsXMk2/cOGCKlasmGX5cePGaezYf+8iEhMTQxDeJBo2vDNfyxmGISn3W68BxeHIkSPWDmF33FEzx+Vq1aptfR4aGmq9dni9FT/8oIiICEk5d4jJTvfu3dW9e/ds5+3Y8ZckqVWr1vleH/LnpjwSdHJyUtOmTbV27VrrtLS0NK1du1atrjnqyODs7CxPT89MDxTMsWPHrB9cvxo1CtT2j23brM+vb9upc2fr80P/DBrOzqFD6fP8/Aq2baCorj1Ff+pkzmciLl7zn/JrT/NfL+NUaK1atdSuXbsi17dz504dOHBAkvTww0OLvD5kdlOGoCSNHTtW33zzjebMmaODBw9q5MiRio+P1/Dhw0u6tFtOxlFWbvNfejH9bhV2dnbq0aNnvttGRkZq0qR3JaXfl7Rx48aZ5levXt16T9CPP/4o2/V9u2yZjh07Jknq2bNXHnsD2Ja/v7/1ZtkzZ/4322FCqamp+ua/6adMvb29s9z+LMOpU6e0dm36L7EMGz6iyGc2EhIS9PTT6WMY+/XrL39//yKtD1ndtCE4cOBAffjhh3rjjTfUqFEj7dq1S8HBwXnesR1ZnTx5Unfd1UJff/WVjh8/bg2itLQ0bdu2TT26d9P336ffFPjxx5/I9AFfMH+++vfrq+++/TbTdZDExET98P33urtNKx3/5zrg++9PzrbjywcffCgnJyft3LlTQwY/pNOnT0tKvwvHt8uW6cknH5eUfo/GoGHDsrRPSkpSRESE9REX/+9tq66dHhERobS0tCK+WzAbV1dXPfLPacuQkBD1vq+X9u7dq7S0NKWlpWnPnj3q2aO7tm7ZIkn6v2fG5Hgrv1mzZiotLU0ODg4KChqWr+3/8ccfeu+9d3XgwAElJydLSr+uGBwcrHb33K3tf/yhatWq6bNp04u+s8iq4AMYbn4Mkcj8+PtYqLULtiTD2dnZ8PHxMZydnTNNHzZsuHElKSVT22uHI0gy3N3djbJlyxr29vaZ1vfZtOm51rBo0RLDxcXF2sbb2zvT9mvVqmUcOnw027bX15Db4+9joSX+fvO49R6xcQlGly5ds3xOrv+MDBr0oJGUfDXbdSSnpBq+vr6GJKNXr/vyve1vv11uXb/FYjHKlCmT6fPVoEED/q4L+CjIEImbsmMMbKtChQr6dOpn2rZ1q3bv3qXw8HBFRUXJxcVFNWrUUKtWrTVs+Ai1adMmS9v2HTrorbff0batW3Xo0EFdunRJ0dHR8vT0VM1atdShQ6Aef/wJ1cjjOmL/AQMU0KiRPp7ykX755WedO3dOTk5Oanjnnerbt59Gjnwq1+ssQHFydXXVj6t+0nfffqsFC+YrJGSHLl68KIvFomrVqql58xYKGjZcPXr0yHEdv/76q06dOiWpYB1imjRtqueef0GbN2/SyRMnFBkZqbJly6phwzs1YMADGjZ8eLY39YZtWAwjj4s+t6CYmBh5eXkpMiqaTjIAYDIxMTEq4+1l/Q97bm7aa4IAABQ3QhAAYFqEIADAtAhBAIBpEYIAANMiBAEApkUIAgBMixAEAJgWIQgAMC1CEABgWoQgAMC0CEEAgGkRggAA0yIEAQCmRQgCAEyLEAQAmBYhCAAwLUIQAGBahCAAwLQIQQCAaRGCAADTIgQBAKZFCAIATIsQBACYFiEIADAtQhAAYFqEIADAtAhBAIBpEYIAANMiBAEApkUIAgBMixAEAJgWIQgAMC1CEABgWoQgAMC0CEEAgGkRggAA0yIEAQCmRQgCAEyLEAQAmBYhCAAwLUIQAGBahCAAwLQIQQCAaRGCAADTIgQBAKZFCAIATIsQBACYFiEIADAtQhAAYFoOtl5haGio9uzZo+rVq6tRo0a2Xj0AADZTqCPBFStWqG/fvtq+fXum6ZMnT1adOnXUt29fNW3aVCNGjLBJkQAAFIdCheDcuXMVHBysevXqWacdOnRIL7/8sgzDUEBAgNzc3DRnzhytXLnSZsUCAGBLhQrBnTt3KiAgQB4eHtZpCxYskCR9/vnnCgkJ0Z9//il7e3t9/fXXtqkUAAAbK1QIRkREqEqVKpmmbdiwQa6urho2bJgkyd/fX3fffbf2799f5CIBACgOhQrBK1euyN7e3vo6NTVVISEhatmypZycnKzTK1eurLCwsKJXCQBAMShUCJYvX15Hjx61vt62bZsSExPVpk2bTMslJibK3d29aBUCAFBMChWCrVu31u7du7Vo0SJFR0fr3XfflcViUadOnTItd/DgQVWuXNkmhQIAYGuFCsGXXnpJDg4OGjx4sMqUKaPVq1erSZMmuueee6zLnD59WocOHVLz5s1tViwAALZUqBBs0qSJfvrpJ7Vr10716tXTsGHD9OOPP2ZaZsmSJfLy8lLHjh1tUigAALZmMQzDKOkibC0mJkZeXl6KjIqWp6dnSZcDALiBYmJiVMbbS9HReWcA9w4FAJgWIQgAMK183UA7MDCw0BuwWCxau3ZtodsDAFBc8hWCGzZsKPQGLBZLodsCAFCc8hWC69evL+46AAC44fIVgu3atSvuOgAAuOHoGAMAMC1CEABgWvk6HZqT8+fP64cfftDhw4cVExOj7MbdWywWzZgxoyibAQCgWBQ6BD/77DO98MILSklJsU7LCMGMHqGGYRCCAICbVqFOh65du1bPPPOMXFxc9PLLL6tVq1aSpK+++krPPfec/Pz8JEljxozRzJkzbVYsAAC2VKgQ/PTTT2WxWLRmzRq98847ql27tiTpscce0+TJk3XgwAEFBQVp5syZatu2rU0LBgDAVgoVgtu3b1eTJk3UsmXLbOc7Ozvriy++kIuLi958880iFQgAQHEpVAhGRUWpZs2a1teOjo6S0n9JPoOzs7Patm3LLdMAADetQoVgmTJlFB8fb33t7e0tSTp16lSm5VJTU3Xp0qUilAcAQPEpVAj6+vrq9OnT1tcNGjSQYRiZflg3Li5OmzdvVtWqVYteJQAAxaBQQyTatWunjz/+WBcuXFCFChXUo0cPubu765VXXlFYWJh8fX01Z84cRUZGatCgQbauGQAAmyhUCA4YMEA7d+7Url271KVLF5UpU0ZTpkzRk08+qSlTpkhKHyPo5+eniRMn2rRgAABsxWJkd5uXQgoJCdHSpUsVGRmpevXqafjw4fLy8rLV6vMtJiZGXl5eioyKlqen5w3fPgCg5MTExKiMt5eio/POgCLdNu16TZo0UZMmTWy5SgAAig030AYAmBYhCAAwrUKdDrW3t8/3shaLRVevXi3MZgAAKFaFCsGC9KWxYb8bAABsqlCnQ9PS0rJ9pKam6vjx45o6daq8vb01fvx4paWl2bpmAABswqa9Qy0Wi/z8/DRq1Cg1aNBAnTp1UoMGDdSvXz9bbgYAAJsoto4x7du3V+PGja2D5wEAuNnY9EjwenfccYdWr15dnJsAkI01v+0t6RKAEpMQH5fvZYt1iMTRo0fpGAMAuGkVSwhevXpV77zzjnbt2qXGjRsXxyYAACiyQp0ODQwMzHFebGysjh8/rsuXL8vOzk6vvPJKoYsDAKA4FSoEN2zYkOcytWvX1qRJk9S1a9fCbAIAgGJXqBBcv359jvOcnJxUpUoV+fr6FrooAABuhEL/qC4AALe6QnWMmTt3rrZs2ZLnctu2bdPcuXMLswkAAIpdoUJw2LBh+u9//5vncjNmzNDw4cMLswkAAIpdsY4TZIwgAOBmVqwhePHiRbm5uRXnJgAAKLR8d4zZtGlTptdhYWFZpmW4evWq9u/fr59//lkNGzYsWoUAABSTfIdg+/btZbFYrK/XrFmjNWvW5NrGMAyNHDmy8NUBAFCM8h2C99xzjzUEN27cqPLly8vf3z/bZZ2cnFS1alX169dP3bt3t02lAADYWL5D8Nq7xNjZ2albt26aOXNmcdQEAMANUeg7xlSsWNHWtQAAcENxxxgAgGkVaohEcHCwAgMDtW7duhyXWbt2rQIDA/XLL78UujgAAIpToUJw1qxZ2r59u5o3b57jMi1atNAff/yh2bNnF7Y2AACKVaFC8K+//lKjRo3k4eGR4zIeHh5q3Lixtm/fXujiAAAoToUKwfPnz+frp5KqVaum8+fPF2YTAAAUu0KFoJOTk2JjY/NcLi4uTnZ2xXpnNgAACq1QCVW7dm39/vvvSkhIyHGZhIQE/f7777rjjjsKXRwAAMWpUCHYq1cvXb58WaNGjcr2lyIMw9Do0aMVHR2t3r17F7lIAACKg8UoxO8dXb58WQ0aNND58+fVuHFjjRgxwnoLtUOHDmnmzJnauXOnKlasqL1796pMmTI2Lzw3MTEx8vLyUmRUtDw9PW/otoGbwZrf9pZ0CUCJSYiP04DurRUdnXcGFGqwfOnSpbVq1Sr16tVLISEh2rlzZ6b5hmGoatWqWrFixQ0PQAAA8qtQIShJAQEBOnTokL755hutWbNGJ0+elCT5+vqqa9euevTRR+Xu7m6zQgEAsLVCnQ7Nj0uXLmnu3LmaOXOm9u69sadmOB0Ks+N0KMys2E+H5sQwDAUHB2vGjBn68ccflZKSYsvVAwBgUzYJwdDQUM2cOVOzZ8/WuXPnrD1GmzRpoqFDh9piEwAA2FyhQzApKUnLli3TjBkztGnTJhmGIcMwZLFY9OKLL2ro0KGqX7++LWsFAMCmChyCO3bs0IwZM7Ro0SJFR0fLMAw5ODioe/fu2rNnj06ePKlJkyYVR60AANhUvkIwKipK8+fP14wZM6ydXAzDkL+/v0aMGKGhQ4eqfPnyatu2rbWXKAAAN7t8hWClSpWUkpIiwzBUqlQpDRw4UCNGjFCrVq2Kuz4AAIpNvkIwOTlZFotFVatW1bx58/hleQDAbSFf9w5t2LChDMPQmTNnFBgYqEaNGmnq1Km6dOlScdcHAECxyVcI7t69W9u3b9fjjz8uDw8P7dmzR88++6yqVKmigQMHas2aNdneSBsAgJtZge8Yk5iYqCVLlmjGjBn67bff0ldisahKlSpKTExUZGSkUlNTi6XY/OKOMTA77hgDMyvIHWMK/FNKrq6uCgoK0qZNm3T48GG9+OKLqlChgs6cOWM9PdqmTRt9/fXXio6OLtweAABwAxTpZ99r166tSZMm6fTp0/r+++/Vs2dP2dnZaevWrRo5cqQqVaqkQYMG2apWAABsqkghmMHe3l733XefVqxYodOnT+udd95RzZo1deXKFS1dutQWmwAAwOZsEoLXqlixosaNG6cjR45o/fr1GjJkiK03AQCATdj0VySu165dO8YUAgBuWjY/EgQA4FZBCAIATIsQBACYFiEIADAtQhAAYFqEIADAtAhBAIBpEYIAANMiBAEApkUIAgBMixAEAJgWIQgAMC1CEABgWoQgAMC0CEEAgGkRggAA0yIEAQCmRQgCAEyLEAQAmBYhCAAwLUIQAGBahCAAwLQIQQCAaRGCAADTIgQBAKZFCAIATIsQBACYFiEIADAtQhAAYFqEIADAtAhBAIBpEYIAANMiBAEApkUIAgBMixAEAJgWIQgAMC1CEABgWoQgAMC0CEEAgGkRggAA0yIEAQCmRQgCAEzLoaQLQMlysLfke9l27dtr7dr1+Vr2qZFP6uuvv5IkVa9eXceOn8izTVhYmD7/fLqCV/+k0NBQJSYmqnz58vL3r6d27dtr7Njn5OjomO96cev4+8gBbd+yUUcPH9C5MycVfTlKCfHxcnN3V1XfGmp2193q0XugPDy9cl1P5KUIrfp+kf7ctlkXzp9VclKSvLzLqFr1GmrYqLn6DhwqB4ec/4YK2v7C+bMaMahbvvezU9feenbcW5mmnTtzStt+X6+9O/9U6PGjioqMkL29vcr6VNB/7myiHn0Gqnbd+rmuNzU1VRt//Ulr16zU8b8PKSEhXl6lvfWfhk10X7/BqtcgINf2KcnJWr1ymTavX6OToX8rOTlJ3mV81KhpS93/wFD5+tXM9z7eaiyGYRglXYStxcTEyMvLS5FR0fL09Czpcm5qVSpXzHV+SkqKIiMjJUnPPf+C3n//gzzXuX79et3buaMy/rTyE4JLFi/Wk08+rpiYGEmSi4uLnJycrK8lKeJSlEqXLp3n9iGt+W1vSZdQIF988q5+XL7I+trJyVn2Dg5KTIi3TvP08tYb707N8Qt907pgffbhm0qIj7Ouw8HR0fpakhb/+JtKeWT/nVCY9uEXwzTmiQdz3beU5GTFx8VKkkaOeUU97x9knXdg7069MCoo0/Kubu5KSUnW1ZQUSZKdnZ0eGPKYHn7k6WzXn5iQoLdfG6NdO7alL29vLzc3dyXExyktLU12dnYa9vgz6vfg8GzbR16K0ISXntKxo4ckSQ4ODnJxdVNcbPpnz9HJSWNenKj2nXvkup83k4T4OA3o3lrR0XlnAEeCJnf2XFiu86dM+UgvvvC8JGnEiEfyXF9CQoKefOIxOTg4KCAgQH/99VeebZYtXaohQx5SWlqaHnvscY3+v2dUv376/3xjY2O1a9cuff/9co4Cb2N1/BtoxMix+k/DxqrqW8MaNIkJCdqy6VfN+OIjRV+O0tuvPaOv56+UeymPTO03r/9Zk996WWlpaeraq7969x9sPXpJSIjX8aOHtHXzOjk4ZP+VV9j25cpX1ILluZ8d+eKT9/Tj8v/J2dlF7Tt1zzTv6tWrsrO3V8tW7dS+c3fd2biFPL1KKzU1VceOHNR/p0/W/r07tWjuVypfsZK69OibZf1TJ0/Qrh3bZGdnp4cfGaWefR+Um5u7YmNjtHTBDH37v1ma+eXHquLrp7vadMjU1jAMvfvGWB07ekjOzi564v9eUofOPeXk7KzIS+Ga/dUnWrtmpT6e9Lqq+NbI84j0VsSRIHLVsEF9HTx4UG3uvlsbN27Oc/mxY5/V1E8/0bhXXtXZM2c0d+6cXI8Ez58/rzsb/kdRUVGa/OFHevbZsTbeA3O61Y4E8xLy5xa9/vyTkqTnX3tPHa45Kom8FK6RQfcrLjZGjz71vO4fOLRA6y5q+9wkJyXp4X4dFRcbow6de+r5197NND/iYpiSkpNUpWr1bNunpKTo2SceVOixI6pUpZr+u3BVpvknjh3R0yP6S5J6Dxiix0e9mGUd7098UZvWBatyFV99NX+F7Oz+7QqyfctGTRw3WpL0+OgX1bv/kCztnxs5RIcO7FFAkxZ69+P/FuwNKCEFORKkYwxytGXLFh08eFCS9MiIR/Ncftu2bZr22VTVqVNHr776Wr628dlnUxUVFaXGjRtrzJhni1Qvbl/+9e+0Po8Iv5Bp3opvFyouNkY1a/urzwMPF3jdRW2fmy2bfrWeVuzSM+tRnE/5ijkGoCQ5OjpaA//82dOKjY3JNP/PP36zPu83aFi26+j3YPr0c2dP6cDekMztt26SJLm4uqpHn4HZtu/7T/vdIdt18cL5HGu9VRGCyNGsmTMkSV5eXuo/YECuyyYlJemxR0fIMAx98eXXcnFxydc25s+bK0l6aPAQWSz576QDc9m3598v70qVq2aat27NSklSh849C/U3VNT2ufn5p+WSpMpVq6tho2aFWoejk7P1eVpqaqZ5F8POSZLcS3morE/5bNtX9a1h3a+QP7dmbv9PqFWq4ptjh6FqvndYn+/8c0sBq7/5cU0Q2YqLi9PSpUskSYMGPSg3N7dcl3/rrTd18OBBPfLIo2rXrl2+thEaGqpz59I/xE2aNNXevXv1/qT3tGHDekVGRqpcuXJq3bqNRo3+P7Vp06ZoO4RbTkpysiIvhWv71k2aP3O6JKlyFV+1bN3eukzY+TO6FHFRklSrbn2dOHZESxbM0J6dfyo2Nlpepb1Vv0Fj3dfvIdVv2DjLNoraPjfnz53Rnp1/SpLu7XF/Yd4CSdLeXenrKFO2nDy9Sme7TFpaWo7tjTTD2kntxPGj2be/Llwzr/vfeTm1v5XdlCG4adMmTZ48WTt27ND58+e1fPly9enTp6TLMpXFixYpLi69V9yIR3I/Fbpz5059OPkDVahQQe9/MDnf2zhy5Ij1+ZYtv+utNycqOTlZrq6ucnFx0dmzZ7V06RItW7ZU4ydM1GuvvV64ncEtpU/nZkpJTs4yvX7Dxnrh9UlydHKyTjt7+qT1+YG9O7Vwzpe6mpIiZ2cXOTk561L4RW1ev0a/bfhZg4c/pQeDnsi0zqK2z80vPy2XYRiyt3dQxy73FeQtsDq4b7e2/Zbe8ebeHn2zHKlWqFhZkpSYEK+LYedU/p/X1zoZ+m9wRUaEZ5qXsfz5s6eVnJQkJ2dnXe9k6N/W55eua387uClPh8bHxysgIEDTp08v6VJMa8bM9AvgAQEBatq0aY7LXb16VY89OkJXr17VJ59MLdAQhstRUdbn4994XZUrV1bwml8UHROnyKho7dm7X+3at5dhGJow/g0t/+67Qu8Pbh3eZXxUukxZubi6Wqfd2bi5Hh/1ospXqJRp2bhrrpHNnzldZcuW09sffa1lwdu09Kct+mLOcjVs1FyGYWj+zOn6fdOvNm2fk9TUVP0a/IMkqXmrtipT1qfA70P05Uh98NZLSktLU+Wq1dU/myEOzVrebX2+aO7X2a5n8bxvrM8TEuIyzWt+V1tJUnJykr5bMifb/Vi6cKb19bVDVm4XN2UIduvWTW+//bbuv7/wpxBQePv379f2P/6QlPdR4PvvT9KuXbvUo0dPDXjggQJt59pTOIZhaMnSb9WpUydr77X69evrhx9WqmLF9LGMb701sUDrx61p1uJgLVi+Xt8G/6EF36/XI089p+N/H9azTz6keTMy/8fYuO5v6JW3pqhxs7usf0O+fjU1/r3P5F0mPYT+N/tLm7bPyY7tv+tSePpp1uyGNeQlMSFBb477P10MOydXN3eNm/ihXLO5JOFXs47ubn+vJGnNqu/0zbTJunD+rK5eTdHZ0yf0yaQ3tH3rJuvQDosl81d+81b3qG79hpKkhbO+1OJ53yjyUriuXk3R8b8P661Xn1Ho34evaX/7Xbe/KUOwoJKSkhQTE5PpgcKbMSP9KNDFxUWDB2ftMp3hwIEDeuftt1SqVClNm/55gbdTyuPfsV6BgR3VpEmTrMuUKqWRT6UPEt6zZ48uXLiQZRncvkp7l1XfgUF6c/IXslgsWjT3K23fstE639XN3fo8oElL1aqTdRybq5ubdYB66LEjioq8ZLP2Ofn5x/SzFmXLlVfTa47W8uNKYoImvPy0Dh3YI1dXN018f7ruqFU3x+WfeWmiApq0kCR9v3SeRgzqpt4dm+rxIffpl9Xf6667O6j5XfdIUpYbBVgsFr361seqUauuUlOvau5/P9PDfTuqd8emGv3IAP25dZN63j9INWrWzbb97eCmvCZYUO+9954mTuQowRaSk5O1cMF8SVLfvv1yPb05evTTSk5O1vgJE+Xt7W29hpjh6tWrktL/h50xz9nZ2TrovUqVKtZl69Wrl+N26tf794vp5MmTqlChQsF2Cre8uvUaqn7Dxtq3e4dWr1ymFq3TO1+VLfdvj8hq1e/Iqbmq+f077+KFc/IuU9Ym7bMTFXlJ2/8ZetCpa2/Z29vnuOz10gNwlPbt3iEXV1dNeH+a/nNn1v8cXsvNzV1vf/S1Nq0L1ub1a3TqxHGlXk1RpSq+Cry3pwK79NLLz4yQJFWplnU4Rlmf8vr4iwX6NfgHbdm8VufPnk7f5+p3qGvPfmrZpr2GPdAlx/a3utsiBMeNG6exY/8dZB0TE6Nq1aqVYEW3rhU//KCIiAhJeZ8KPREaKkl69ZVxevWVcTkud+rUKZX2Sj/q+2jKx3rmmTGS0k932tvbKzWXnmmSdO39HG7H0zHIn4whABlf0pLkW72m7Oztc+3dKEm69m9I//4NFbV9dtatWaHU1KuyWCzq3D3/l3QyAnDvrr/k7OKiCZOmq0FA/oZV2NnZqX2n7lnuSCNJqVevKvRYeie0ev9plG17RycndbtvgLrdl3Uo1OWoSwr/ZyhFvQbZt7+V3RanQ52dneXp6ZnpgcLJOBVaq1atfA91KCwXFxe1vSf9NE3GoPzsHDh4QFJ6APr5+RVrTbh5hZ0/I0mZro05OTurwT9HSqdPHs+x7akT6fMsFosqVPq3B2VR22cnY2zgnY2bZxnTmJMriQka/9LT2rvrL7m4umri+58Xelzh9f7YslHxcbFydnbR3R3uLXD79b/8JCn9qDmgcQub1HQzuS1CELZx6tQprV2b3vtt2PAReR51HTt+QldTjRwfQ4em3xi4evXq1mkZR4EZhgWl93hbt26tQkJCrt+E4uLi9OUX6dcbW7RsqXLlyhV1N3GTSU1NVV53b9y1Y5uOHNwnSWrYqHmmeZ279ZEk7Q75Q38fOZClbWJCglZ9v1hS+mlVr9JlbNr+Wvv3hOjMqROS0oc05EdGAGacAp34/nSbBWD05UjN+OIjSVKP+wfKo4DX9M6fPa1Fc9N/DeaBwY/KPod7r97KbsoQjIuL065du7Rr1y5J6YOqd+3apVOnTpVsYbe5WbNmKi0tTQ4ODgoKGnZDtvnQ4MFq3qKFDMPQAwP6ae3atdZeowcPHlSfPvcpLCxMdnZ2euutd25ITbixIi6GafSjD2j1iqU6f+5MpkAMvximJQtm6K1Xn5FhGPLw9FKfAZlvbda+cw/Vqdcg/WbQr4/Vrh3brH9Dp04c15uvjFZUZITs7Ow09LHRWbZf1PbXWrMqvUOMh6eX2tzTKc99v3IlURNeHq19u3f80wnm83yfAs2wfesm/bBsvs6fPW29tHDlSqI2r/9Zzz31sMLOnVGNWnU1ZET2v0KxNniFglcuU8TFMOt+x8fFas2q7/T80w8rLjZGTVu0yfG2are6mzLW//rrL3Xo8O/dzjOu9wUFBWn27NklVNXtLS0tTXNmz5IkdevWXZUqVcqjhW3Y2dlp+fIfdG/njjpw4IC63NtJbm5ucnR0VHR0tKT0+yd+9tl0BQYG3pCacOOF/n1Y0z5K/509B0dHubmVUnLyFV1JTLQuU6FSFb365pQsY+7s7Oz0+jtT9erYx3TqxDG9OvZxObu4yMHB0foTRg4ODho55hUFNGmZZdtFbZ8hIT5Ov234WZLUoXOPTIP6c/L7hl+sd4RJTU3VexOez3X5V9/6WPWvuy537sxJfTNtsr7+7IMsP6MkSQ0Cmuq1tz+Rs3P2tzI8dvSgfli2wLqfzi6uSoiPs/5npE27znr+1Xdv2+vxN2UItv9ngDRunF9//dV6pJ1Xhxhbq1ixov78K0TTp0/TkiWLdfTIESUmJsrPz08dOgTqmTHPqkGDBje0Jtw4ZXzKa9zED7V31186fGCvIi+FKzo6SvZ29ipXoZJq1Kyju+7uoPaduuf4RV6mrI+mfrNYK5f/T5vXrdHZMyeVlHRFFSpW1p1NWqrPgCHyu6N2zjUUsb0kbVwbrKQrVyTlf2xg2jXfc8nJSUqOTMp1+YzfGLxW42at1KvvQzqwN0ThFy8oISFOpb3Lqrb/f9ShUw/d3eHeXAOsbYeuunLlig7t361LEReVlHRFPuUqqF6DRurUrbeatri9b1nITykBt6Hb7aeUgILgp5QAAMgHQhAAYFqEIADAtAhBAIBpEYIAANMiBAEApkUIAgBMixAEAJgWIQgAMC1CEABgWoQgAMC0CEEAgGkRggAA0yIEAQCmRQgCAEyLEAQAmBYhCAAwLUIQAGBahCAAwLQIQQCAaRGCAADTIgQBAKZFCAIATIsQBACYFiEIADAtQhAAYFqEIADAtAhBAIBpEYIAANMiBAEApkUIAgBMixAEAJgWIQgAMC1CEABgWoQgAMC0CEEAgGkRggAA0yIEAQCmRQgCAEyLEAQAmBYhCAAwLUIQAGBahCAAwLQIQQCAaRGCAADTIgQBAKZFCAIATIsQBACYFiEIADAtQhAAYFqEIADAtAhBAIBpEYIAANMiBAEApkUIAgBMixAEAJgWIQgAMC1CEABgWoQgAMC0CEEAgGkRggAA0yIEAQCmRQgCAEyLEAQAmBYhCAAwLUIQAGBahCAAwLQIQQCAaRGCAADTIgQBAKZFCAIATIsQBACYFiEIADAtQhAAYFqEIADAtAhBAIBpEYIAANMiBAEApkUIAgBMixAEAJgWIQgAMC1CEABgWoQgAMC0CEEAgGkRggAA0yIEAQCmRQgCAEyLEAQAmJZDSRdQHAzDkCTFxMSUcCVAyUiIjyvpEoASk5AQL+nfLMjNbRmCsbGxkiS/6tVKuBIAQEmJjY2Vl5dXrstYjPxE5S0mLS1N586dk4eHhywWS0mXYzoxMTGqVq2aTp8+LU9Pz5IuB7jh+AyULMMwFBsbq8qVK8vOLverfrflkaCdnZ2qVq1a0mWYnqenJ18AMDU+AyUnryPADHSMAQCYFiEIADAtQhA25+zsrPHjx8vZ2bmkSwFKBJ+BW8dt2TEGAID84EgQAGBahCAAwLQIQQCAaRGCMBU/Pz9ZLJZMD2dnZ/n6+mrgwIHavHlzSZcoSZowYYIsFosmTJiQafrs2bNlsVg0bNiwYq/hxIkTslgs8vPzK/ZtASWFEIQptWnTRkFBQQoKClK3bt2UlpamJUuWqF27dpoyZUpJl3dDZPyH4MSJEyVdClBibss7xgB5efTRRzMdTV25ckVPPPGE5s6dqxdffFE9e/ZUnTp1Sq7AHNx///2666678n03jKKoUqWKDh48KEdHx2LfFlBSOBIEJLm4uGj69Olyd3dXamqqvvvuu5IuKVteXl7y9/dXpUqVin1bjo6O8vf3V82aNYt9W0BJIQSBf5QqVUp169aVJOspwozrhpI0a9YstWrVSl5eXllOI547d05jx45VvXr15ObmJg8PDzVv3lzTpk3T1atXs91eYmKiJkyYoNq1a8vZ2VmVKlVSUFCQTp06lWONeV0TPHv2rF544QU1bNhQHh4ecnd3V506dTRs2DBt2bIl0zpOnjwpSapRo0ama6QbNmywvge5XRM8c+aMRo8erdq1a8vFxUVeXl5q06aNvvrqK6WmpuZae3x8vMaNG6datWrJ2dlZFStWVFBQkM6ePZvttn799Vf16tVLFSpUkKOjo7y9vVW7dm0NGTJEmzZtyvH9AvLC6VDgGhm/QXn9nT5Gjx6tzz//XK1bt1aPHj10/Phxazhu2rRJffr0UVRUlPz8/NS5c2clJSVp+/btGj16tFauXKkff/wx02nFhIQEdezYUdu2bZO7u7vuvfdeubq6as2aNVq1apV69OhR4NrXrl2r/v376/Llyypfvrw6duwoJycnnThxQgsXLpQktW7dWrVq1VJQUJCWLVum+Ph49evXT6VKlbKup2LFinlu688//1TXrl0VGRkpX19f9enTR9HR0dqwYYO2bNmi5cuXa8WKFXJycsrSNjo6Wq1bt9apU6fUtm1bNWjQQFu3btXcuXO1ceNG7d69O9Pp3jlz5mj48OGSpBYtWqhDhw5KTEzUmTNntGjRIvn4+Oiee+4p8PsFSJIMwESqV69uSDJmzZqVZd7u3bsNOzs7Q5Ixc+ZMwzAMQ5IhyfD09DS2bt2apc358+eNsmXLGhaLxfj888+N1NRU67yIiAgjMDDQkGRMnDgxU7vnn3/ekGT4+/sbZ8+etU6Pj483evfubd3u+PHjM7WbNWuWIckICgrKNP3UqVOGl5eXIcl4+eWXjaSkpEzzL1y4YGzevDnb9yI0NDTb9yo0NNSQZFSvXj3T9CtXrljbPvnkk0ZycrJ13rFjxww/Pz9DkvHKK69kW7sko0uXLkZ0dLR1XmRkpNGoUSNDkvHuu+9malejRg1DUpb6M/YrJCQk2/qB/CAEYSrZheDly5eNVatWGTVr1jQkGZUrVzbi4uIMw/g3BN98881s1/fSSy8ZkoxRo0ZlO//MmTOGo6OjUa5cOSMtLc0wDMNISEgwPDw8DEnG6tWrs7Q5f/684eLiUqAQHDNmjCHJ6NWrVz7ficKH4Lx586zv05UrV7K0W7ZsmSHJ8PDwMBITE7PU7u7ubpw7dy5Lu0WLFhmSjMDAwEzT3dzcDC8vr3zvF1AQXBOEKQ0fPtx6Dax06dLq0aOHjh07ppo1a+qnn36Su7t7puX79++f7XpWrVolSRo4cGC286tUqaLatWsrPDxcR48elSSFhIQoNjZWPj4+6tq1a5Y2FStW1L333lug/QkODpYkPf744wVqVxgZ1wwHDRqU7Q2i+/btK29vb8XGxmrHjh1Z5jdr1izbjj316tWTpCzXBVu0aKHo6GgNHTpUO3bsUFpamg32AkjHNUGYUps2bVSrVi1JkpOTk8qXL6+77rpLXbt2lYND1o9FTp1Djh8/Lklq27ZtntsMDw9XnTp1dObMmVzXKaV3VimIjE4u/v7+BWpXGBkhlVONFotFNWrUUFRUVLYdXXx9fbNtl/Hjs1euXMk0/fPPP1fPnj01b948zZs3z9rpKDAwUA8//HCO6wPygxCEKV0/TjAvrq6u2U7POCrp379/lqPH65UtWzbf27ud2dkV7ARUvXr1dPjwYf38889at26dtmzZos2bN2vdunV68803NWPGDA0ZMqSYqsXtjhAEiqBatWo6evSoXnrpJTVr1ixfbapUqSJJud6ppaB3cfH19dXhw4d16NAh6xFuccmoP+MoODuhoaGZli0qBwcHde/eXd27d5eU3ot3ypQpmjhxop544gndf//9ef4nBMgO1wSBIujWrZskacmSJflu07RpU5UqVUoRERH6+eefs8y/cOFCttNzk3Ft8Ztvvsl3m4zhCzmNY8xJ+/btJUmLFy/OcupSkpYvX66oqCh5eHioadOmBVp3fnl6emrChAkqXbq0EhISdOTIkWLZDm5/hCBQBC+88IJKly6tKVOm6KOPPlJycnKWZUJDQzV//nzra1dXV2sHlmeffVbnz5+3zktMTNTIkSOVmJhYoDrGjh0rDw8PrVixQq+99ppSUlIyzb948aJ+++23TNOqVq0qSdq/f3+BtjVgwAD5+vpabxBwbYiGhobqueeek5Q+ttLFxaVA675eQkKCpkyZovDw8CzzNm/erMuXL8ve3t66L0CBlXT3VOBGym2cYHb0zxCJ3GzcuNHw8fExJBnly5c3AgMDjcGDBxs9e/a0Drto2bJlpjZxcXFGixYtDElGqVKljF69ehkDBgwwKlasaJQtW9YYOnRogYZIGIZhrFmzxjr0okKFCkafPn2MAQMGGC1atDAcHR2ztJk2bZp1+3379jUeeeQR45FHHjEOHTpkGEbOQyQMwzC2b99ulClTxjp/4MCBRvfu3a1DO7p06ZJlrGJutee0vaioKEOSYWdnZwQEBBj9+/c3HnzwQaNVq1aGxWIxJBlvvPFGtusD8oNrgkAR3XPPPdq/f7+mTZumVatW6c8//1RSUpLKly8vX19fDRkyRP369cvUxt3dXevXr9ekSZO0cOFCrVmzRt7e3urUqZPefvttzZ49u8B13Hvvvdq3b5+mTJmi4OBgBQcHy8HBQZUrV9bDDz+sxx57LNPyI0eOVGxsrObPn6+ffvrJempzyJAh1tvH5aR58+batWuX3n//fa1evVrLly+Xs7OzGjdurKFDh+rRRx/NtpdtQZUqVUpffvmlNm7cqJ07d+qXX35RcnKyKleurL59++qpp55SYGBgkbcD87IYhmGUdBEAAJQErgkCAEyLEAQAmBYhCAAwLUIQAGBahCAAwLQIQQCAaRGCAADTIgQBAKZFCAIATIsQBACYFiEIADAtQhAAYFqEIADAtP4fmqAtjChuq5UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (5, 5))\n",
    "ax.matshow(conf_matrix, cmap = plt.cm.Blues, alpha = 0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x = j, y = i,s = conf_matrix[i, j], va = 'center', ha = 'center', fontsize = 18)\n",
    " \n",
    "plt.xlabel('Predictions', fontsize = 16)\n",
    "plt.ylabel('Actuals', fontsize = 16)\n",
    "plt.savefig(\"Results/Confusion Matrix/Botiot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe6750e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
