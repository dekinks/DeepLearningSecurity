{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd6b254",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pandas\n",
    "!pip3 install --upgrade tensorflow-gpu\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.layers import Lambda, Input, Dense, Dropout, Conv1D, MaxPooling1D, Flatten, BatchNormalization\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97acbba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(path):\n",
    "    \n",
    "    all_files = glob.glob(os.path.join(path , '*.csv'))\n",
    "\n",
    "    files_list = []\n",
    "    for file in all_files:\n",
    "        df = pd.read_csv(file, index_col = None, encoding = 'utf-8', sep = ',', low_memory = False)\n",
    "        files_list.append(df)\n",
    "        \n",
    "    df = pd.concat(files_list, axis = 0, ignore_index = True)\n",
    "    \n",
    "    # Get only the attacks\n",
    "    df = df.query('attack == 1')\n",
    "    df = df.drop(columns=['attack'])\n",
    "    \n",
    "    # Drop irrelevant information\n",
    "    df = df.drop(columns=['pkSeqID', 'stime', 'flgs', 'flgs_number', 'saddr', 'sport', 'daddr', 'dport', 'subcategory'])\n",
    "    \n",
    "    # Categorical to numerical\n",
    "    df['proto'] = df['proto'].map({'tcp': 1, 'arp': 2, 'udp': 3, 'icmp': 4, 'ipv6-icmp': 5})\n",
    "    df['state'] = df['state'].map({'REQ': 1, 'RST': 2, 'ACC': 3, 'CON': 4, 'INT': 5, 'URP': 6, 'FIN': 7, 'NRS': 8, 'ECO': 9, 'TST': 10, 'MAS': 11})\n",
    "    df['category'] = df['category'].map({'DDoS': 0, 'DoS': 1, 'Reconnaissance': 2, 'Theft': 3})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca5cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_nbaiot_mirai(path):\n",
    "    \n",
    "    all_files = glob.glob(os.path.join(path , '*.csv'))\n",
    "\n",
    "    files_list = []\n",
    "    for file in all_files:\n",
    "        if ('ack' in file):\n",
    "            df = pd.read_csv(file, index_col = None, encoding = 'utf-8', sep = ',', low_memory = False)\n",
    "            df['category'] = 0\n",
    "        elif ('scan' in file):\n",
    "            df = pd.read_csv(file, index_col = None, encoding = 'utf-8', sep = ',', low_memory = False)\n",
    "            df['category'] = 1\n",
    "        elif ('syn' in file):\n",
    "            df = pd.read_csv(file, index_col = None, encoding = 'utf-8', sep = ',', low_memory = False)\n",
    "            df['category'] = 2\n",
    "        elif ('udp' in file and 'udpplain' not in file):\n",
    "            df = pd.read_csv(file, index_col = None, encoding = 'utf-8', sep = ',', low_memory = False)\n",
    "            df['category'] = 3\n",
    "        elif ('udpplain' in file):\n",
    "            df = pd.read_csv(file, index_col = None, encoding = 'utf-8', sep = ',', low_memory = False)\n",
    "            df['category'] = 4\n",
    "            \n",
    "        files_list.append(df)\n",
    "        \n",
    "    df = pd.concat(files_list, axis = 0, ignore_index = True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8defca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_nbaiot_gafgyt(path):\n",
    "    \n",
    "    all_files = glob.glob(os.path.join(path , '*.csv'))\n",
    "\n",
    "    files_list = []\n",
    "    for file in all_files:\n",
    "        if ('combo' in file):\n",
    "            df = pd.read_csv(file, index_col = None, encoding = 'utf-8', sep = ',', low_memory = False)\n",
    "            df['category'] = 5\n",
    "        elif ('junk' in file):\n",
    "            df = pd.read_csv(file, index_col = None, encoding = 'utf-8', sep = ',', low_memory = False)\n",
    "            df['category'] = 6\n",
    "        elif ('scan' in file):\n",
    "            df = pd.read_csv(file, index_col = None, encoding = 'utf-8', sep = ',', low_memory = False)\n",
    "            df['category'] = 7\n",
    "        elif ('tcp' in file):\n",
    "            df = pd.read_csv(file, index_col = None, encoding = 'utf-8', sep = ',', low_memory = False)\n",
    "            df['category'] = 8\n",
    "        elif ('udp' in file):\n",
    "            df = pd.read_csv(file, index_col = None, encoding = 'utf-8', sep = ',', low_memory = False)\n",
    "            df['category'] = 9\n",
    "            \n",
    "        files_list.append(df)\n",
    "        \n",
    "    df = pd.concat(files_list, axis = 0, ignore_index = True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf792d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_nbaiot_gafgyt_edsw(path):\n",
    "    \n",
    "    all_files = glob.glob(os.path.join(path , '*.csv'))\n",
    "\n",
    "    files_list = []\n",
    "    for file in all_files:\n",
    "        if ('combo' in file):\n",
    "            df = pd.read_csv(file, index_col = None, encoding = 'utf-8', sep = ',', low_memory = False)\n",
    "            df['category'] = 0\n",
    "        elif ('junk' in file):\n",
    "            df = pd.read_csv(file, index_col = None, encoding = 'utf-8', sep = ',', low_memory = False)\n",
    "            df['category'] = 1\n",
    "        elif ('scan' in file):\n",
    "            df = pd.read_csv(file, index_col = None, encoding = 'utf-8', sep = ',', low_memory = False)\n",
    "            df['category'] = 2\n",
    "        elif ('tcp' in file):\n",
    "            df = pd.read_csv(file, index_col = None, encoding = 'utf-8', sep = ',', low_memory = False)\n",
    "            df['category'] = 3\n",
    "        elif ('udp' in file):\n",
    "            df = pd.read_csv(file, index_col = None, encoding = 'utf-8', sep = ',', low_memory = False)\n",
    "            df['category'] = 4\n",
    "            \n",
    "        files_list.append(df)\n",
    "        \n",
    "    df = pd.concat(files_list, axis = 0, ignore_index = True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac6a200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attack(attack_type, df):\n",
    "    \n",
    "    df = df.query('category==' + str(attack_type))\n",
    "    label = df.pop('category') \n",
    "    df = df.sample(frac=1)\n",
    "    \n",
    "    return df, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe47af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model with 1D convolutional layer for nbaiot dataset\n",
    "\n",
    "def CNN(feature, depth, number_classes):\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv1D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_uniform', input_shape = (feature, depth)))\n",
    "    model.add(layers.MaxPooling1D(pool_size = 2, strides = 2))\n",
    "    model.add(layers.Conv1D(64, 3, activation='relu', padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "    model.add(layers.MaxPooling1D(pool_size = 2, strides = 2))\n",
    "    model.add(layers.Conv1D(64, 3, activation='relu', padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation = 'relu'))\n",
    "    model.add(layers.Dense(number_classes, activation = 'softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fdf3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, Y_train, X_val, Y_val, epochs, batch_size, reduce_lr, model):\n",
    "    \n",
    "    train_start = time.time()\n",
    "\n",
    "    history = model.fit(X_train, Y_train, \n",
    "                        epochs = epochs, \n",
    "                        batch_size = batch_size, \n",
    "                        validation_data = (X_val, Y_val),\n",
    "                        callbacks = [reduce_lr])\n",
    "\n",
    "    train_end = time.time()\n",
    "    train_time = train_end - train_start\n",
    "    print(\"Training time:\", train_time)\n",
    "    \n",
    "    return model, train_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb72c3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_openset(X_test, model):\n",
    "    \n",
    "    test_start = time.time()\n",
    "\n",
    "    Y_pred = model.predict(X_test)\n",
    "\n",
    "    test_end = time.time()\n",
    "    test_time = test_end - test_start\n",
    "    print(\"Testing time:\", test_time)\n",
    "    \n",
    "    pred = []\n",
    "    for idx, x in enumerate(Y_pred[:100]):\n",
    "        print(x)\n",
    "        aux = []\n",
    "        for i in x:\n",
    "            if i < 0.1:\n",
    "                aux.append(False)\n",
    "            else:\n",
    "                aux.append(True)\n",
    "        \n",
    "        print(aux)\n",
    "        if True in aux:\n",
    "            pred.append(np.argmax(np.asarray(x)))\n",
    "        else:\n",
    "            pred.append(2)\n",
    "        \n",
    "    pred = np.asarray(pred)\n",
    "    \n",
    "    return pred, test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f01115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X_test, model):\n",
    "    \n",
    "    test_start = time.time()\n",
    "\n",
    "    Y_pred = model.predict(X_test)\n",
    "\n",
    "    test_end = time.time()\n",
    "    test_time = test_end - test_start\n",
    "    print(\"Testing time:\", test_time)\n",
    "    \n",
    "    pred = np.argmax(Y_pred, axis = 1)\n",
    "    \n",
    "    return pred, test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe3af61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(Y_test, Y_pred, labels):\n",
    "    \n",
    "    acc = accuracy_score(Y_test, Y_pred) \n",
    "    f1 = f1_score(Y_test, Y_pred, average = 'weighted')\n",
    "    pre = precision_score(Y_test, Y_pred, labels = None, pos_label = 1, average = 'weighted')\n",
    "    rec = recall_score(Y_test, Y_pred, labels = None, pos_label = 1, average = 'weighted', sample_weight = None)\n",
    "    \n",
    "    return acc, f1, pre, rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9e27f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(learning_rate,\n",
    "                  epochs,\n",
    "                  batch_size,\n",
    "                  X_train,\n",
    "                  X_val,\n",
    "                  X_test,\n",
    "                  opt_time,\n",
    "                  train_time,\n",
    "                  test_time,\n",
    "                  acc,\n",
    "                  f1,\n",
    "                  pre,\n",
    "                  rec,\n",
    "                  Y_test,\n",
    "                  Y_pred,\n",
    "                  model_type,\n",
    "                  path):\n",
    "    \n",
    "    stdout_obj = sys.stdout\n",
    "    sys.stdout = open(path, \"a\")\n",
    "\n",
    "    print(\"==== Experiment \" + model_type + \" ====\")\n",
    "    print(\"Learning rate:\" + str(learning_rate) + \" - Epochs:\" + str(epochs) + \" - Batch size:\" + str(batch_size))\n",
    "    print(\"Training size:\" + str(len(X_train)) + \" - Testing size:\" + str(len(X_test)))\n",
    "    print(\"Optimization time:\" + str(opt_time) + \" - Training time:\" + str(train_time) + \" - Testing time:\" + str(test_time))\n",
    "    print(\"Accuracy:\" + str(acc))\n",
    "    print(\"F1-score:\" + str(f1))\n",
    "    print(\"Precision:\" + str(pre))\n",
    "    print(\"Recall:\" + str(rec))\n",
    "    print(classification_report(Y_test, Y_pred, digits = 5))\n",
    "    print(\"=================================================================\")\n",
    "\n",
    "    sys.stdout = stdout_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f284af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nb_knn(X_train, Y_train, nb_knn_model):\n",
    "    \n",
    "    train_start = time.time()\n",
    "\n",
    "    nb_knn_model.fit(X_train, Y_train)\n",
    "\n",
    "    train_end = time.time()\n",
    "    train_time = train_end - train_start\n",
    "    \n",
    "    return nb_knn_model, train_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc520bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nb_knn(X_test, nb_knn_model):\n",
    "    \n",
    "    test_start = time.time()\n",
    "\n",
    "    Y_pred = nb_knn_model.predict(X_test)\n",
    "\n",
    "    test_end = time.time()\n",
    "    test_time = test_end - test_start\n",
    "    print(\"Testing time:\", test_time)\n",
    "        \n",
    "    return Y_pred, test_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
