{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0292919c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/andressa.amaral/.local/lib/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in /home/andressa.amaral/.local/lib/python3.7/site-packages (0.11.2)\n",
      "Requirement already satisfied: pandas>=0.23 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from seaborn) (1.3.5)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from seaborn) (1.21.5)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from seaborn) (3.5.1)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from seaborn) (1.7.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (4.31.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (9.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (3.0.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (1.4.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pandas>=0.23->seaborn) (2022.1)\n",
      "Requirement already satisfied: typing-extensions in /home/andressa.amaral/.local/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=2.2->seaborn) (4.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow-gpu in /home/andressa.amaral/.local/lib/python3.7/site-packages (2.10.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (2.0.7)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (0.4.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: packaging in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (21.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.44.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (4.1.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (3.6.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.1.2)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (3.19.4)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (13.0.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.14.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.21.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (0.24.0)\n",
      "Requirement already satisfied: setuptools in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (60.10.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.30.0)\n",
      "Requirement already satisfied: cached-property in /home/andressa.amaral/.local/lib/python3.7/site-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (2.0.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (2.6.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (0.4.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from packaging->tensorflow-gpu) (3.0.7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow-gpu) (4.11.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2018.1.18)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow-gpu) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu) (3.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: import-ipynb in /home/andressa.amaral/.local/lib/python3.7/site-packages (0.1.3)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: cuda-python in /home/andressa.amaral/.local/lib/python3.7/site-packages (11.8.0)\n",
      "Requirement already satisfied: cython in /home/andressa.amaral/.local/lib/python3.7/site-packages (from cuda-python) (0.29.32)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mimporting Jupyter notebook from AttackClassificationModel.ipynb\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/andressa.amaral/.local/lib/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow-gpu in /home/andressa.amaral/.local/lib/python3.7/site-packages (2.10.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: packaging in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (21.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (0.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (3.19.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (13.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.44.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.0.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.1.2)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (2.0.7)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.14.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (4.1.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (3.6.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (0.24.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.21.5)\n",
      "Requirement already satisfied: setuptools in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (60.10.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.30.0)\n",
      "Requirement already satisfied: cached-property in /home/andressa.amaral/.local/lib/python3.7/site-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (2.6.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (2.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (2.27.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (3.3.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from packaging->tensorflow-gpu) (3.0.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow-gpu) (4.11.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2018.1.18)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (1.22)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow-gpu) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu) (3.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas\n",
    "!pip3 install seaborn\n",
    "!pip3 install --upgrade tensorflow-gpu\n",
    "!pip3 install import-ipynb\n",
    "!pip3 install cuda-python\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import math\n",
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import import_ipynb\n",
    "import AttackClassificationModel\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edea824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction = 0.333)\n",
    "sess = tf.compat.v1.Session(config = tf.compat.v1.ConfigProto(gpu_options = gpu_options))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fd928e",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b93bc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_traffic = AttackClassificationModel.get_files(\"../../botiot\")\n",
    "\n",
    "# Get DDoS\n",
    "df_ddos, label_ddos = AttackClassificationModel.get_attack(0, df_traffic)\n",
    "\n",
    "# Get DoS\n",
    "df_dos, label_dos = AttackClassificationModel.get_attack(1, df_traffic)\n",
    "\n",
    "# Get Reconaissance\n",
    "df_rec, label_rec = AttackClassificationModel.get_attack(2, df_traffic)\n",
    "\n",
    "# Get Theft\n",
    "df_theft, label_theft = AttackClassificationModel.get_attack(3, df_traffic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "013fc29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize with the min-max scaler\n",
    "scaler = MinMaxScaler()\n",
    "df_ddos_norm = scaler.fit_transform(df_ddos)\n",
    "df_dos_norm = scaler.fit_transform(df_dos)\n",
    "df_rec_norm = scaler.fit_transform(df_rec)\n",
    "df_theft_norm = scaler.fit_transform(df_theft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c24877a",
   "metadata": {},
   "source": [
    "# Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1a6eb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "len_ddos_train = int(0.7 * len(df_ddos_norm))\n",
    "X_ddos_train = df_ddos_norm[:len_ddos_train]\n",
    "\n",
    "len_dos_train = int(0.7 * len(df_dos_norm))\n",
    "X_dos_train = df_dos_norm[:len_dos_train]\n",
    "\n",
    "X_train = np.concatenate([X_ddos_train, X_dos_train])\n",
    "Y_train = np.concatenate([label_ddos[:len_ddos_train], label_dos[:len_dos_train]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd5d8006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "len_ddos_test = len_ddos_train + int(0.15 * len(df_ddos_norm))\n",
    "X_ddos_test = df_ddos_norm[len_ddos_train : len_ddos_test]\n",
    "\n",
    "len_dos_test = len_ddos_train + int(0.15 * len(df_dos_norm))\n",
    "X_dos_test = df_dos_norm[len_dos_train : len_dos_test]\n",
    "\n",
    "X_rec_test = df_rec_norm\n",
    "\n",
    "label_theft = []\n",
    "X_theft_test = df_theft_norm\n",
    "for i in range(len(X_theft_test)):\n",
    "    label_theft.append(2)\n",
    "\n",
    "X_test_opt = np.concatenate([X_ddos_test, X_dos_test])\n",
    "Y_test_opt = np.concatenate([label_ddos[len_ddos_train : len_ddos_test], label_dos[len_dos_train : len_dos_test]])\n",
    "\n",
    "X_test = np.concatenate([X_ddos_test, X_dos_test, X_rec_test, X_theft_test])\n",
    "Y_test = np.concatenate([label_ddos[len_ddos_train : len_ddos_test], label_dos[len_dos_train : len_dos_test], label_rec, label_theft])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9db62c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "X_ddos_val = df_ddos_norm[len_ddos_test:]\n",
    "X_dos_val = df_dos_norm[len_dos_test:]\n",
    "\n",
    "X_val = np.concatenate([X_ddos_val, X_dos_val])\n",
    "Y_val = np.concatenate([label_ddos[len_ddos_test:], label_dos[len_dos_test:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7beac3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "X_test_opt = np.reshape(X_test_opt, (X_test_opt.shape[0], X_test_opt.shape[1], 1))\n",
    "X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n",
    "\n",
    "samples, feature, depth = X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0fed11",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e3e83e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial values\n",
    "batch_size = 50\n",
    "number_features = 35\n",
    "learning_rate = 0.008\n",
    "epochs = 1\n",
    "\n",
    "# Dictionary\n",
    "dict_params = { 'learning_rate': learning_rate, 'batch_size': round(batch_size), 'epochs': round(epochs) }\n",
    "pbounds = { 'learning_rate': (0.000001, 0.001), 'batch_size': (10, 30), 'epochs': (1, 50) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf3635d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = AttackClassificationModel.CNN_botiot(feature, depth)\n",
    "reduce_lr = ReduceLROnPlateau(moniter = 'val_loss', factor = 0.1, patience = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae1189e",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69d46a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximize_training(X_train = X_train,\n",
    "                      Y_train = Y_train, \n",
    "                      X_val = X_val, \n",
    "                      Y_val = Y_val, \n",
    "                      X_test = X_test_opt, \n",
    "                      Y_test = Y_test_opt, \n",
    "                      learning_rate = learning_rate, \n",
    "                      epochs = epochs, \n",
    "                      batch_size = batch_size,\n",
    "                      reduce_lr = reduce_lr):\n",
    "    \n",
    "    nadam = optimizers.Nadam(learning_rate = dict_params['learning_rate'], beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08, schedule_decay = 0.004)\n",
    "    model = AttackClassificationModel.CNN_botiot(feature, depth)\n",
    "    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"nadam\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    history = model.fit(X_train, Y_train, \n",
    "                        epochs = dict_params['epochs'], \n",
    "                        batch_size = dict_params['batch_size'], \n",
    "                        validation_data = (X_val, Y_val),\n",
    "                        callbacks = [reduce_lr],\n",
    "                        verbose = 0)\n",
    "\n",
    "    scores = model.evaluate(X_test, Y_test)\n",
    "    return scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcbb0ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Apply Bayesian optimization to choose the best hyperparameters\\n\\nopt = BayesianOptimization(f = maximize_training,\\n                           pbounds = pbounds,\\n                           verbose = 2, \\n                           random_state = 1)\\n\\nopt_start = time.time()\\n\\nopt.maximize(init_points = 5, n_iter = 5)\\n\\nopt_end = time.time()\\nopt_time = opt_end - opt_start\\nprint(\"Optimization time:\", opt_time)\\n\\nlearning_rate = opt.max[\\'params\\'][\\'learning_rate\\']\\nepochs = round(opt.max[\\'params\\'][\\'epochs\\'])\\nbatch_size = round(opt.max[\\'params\\'][\\'batch_size\\'])\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Apply Bayesian optimization to choose the best hyperparameters\n",
    "\n",
    "opt = BayesianOptimization(f = maximize_training,\n",
    "                           pbounds = pbounds,\n",
    "                           verbose = 2, \n",
    "                           random_state = 1)\n",
    "\n",
    "opt_start = time.time()\n",
    "\n",
    "opt.maximize(init_points = 5, n_iter = 5)\n",
    "\n",
    "opt_end = time.time()\n",
    "opt_time = opt_end - opt_start\n",
    "print(\"Optimization time:\", opt_time)\n",
    "\n",
    "learning_rate = opt.max['params']['learning_rate']\n",
    "epochs = round(opt.max['params']['epochs'])\n",
    "batch_size = round(opt.max['params']['batch_size'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bf9934",
   "metadata": {},
   "source": [
    "# Classify Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36416416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training step with the best hyperparameters\n",
    "learning_rate = 0.0006855342808963628\n",
    "epochs = 1\n",
    "batch_size = 21\n",
    "opt_time = 3915.1859345436096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "962212a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Train on 2503818 samples, validate on 343080 samples\n",
      "2503818/2503818 [==============================] - ETA: 0s - loss: 6.0657e-04 - accuracy: 0.9999"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andressa.amaral/.local/lib/python3.7/site-packages/keras/engine/training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2503818/2503818 [==============================] - 505s 202us/sample - loss: 6.0657e-04 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Training time: 505.62210178375244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andressa.amaral/.local/lib/python3.7/site-packages/keras/engine/training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing time: 30.75585126876831\n",
      "[9.9999994e-01 1.2292906e-35]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.2290844e-35]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.2288687e-35]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.2192497e-35]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.5039354e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.5036600e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.5034075e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.5031552e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.5028916e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.5026278e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.5023757e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.5021464e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.5018715e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.5016079e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.5013673e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.5011040e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.5008405e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.5005772e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.5003253e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4999934e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4997417e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4996159e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.8332193e-33]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.8336529e-33]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.8339328e-33]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.8340728e-33]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.8343666e-33]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.8346466e-33]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.8350525e-33]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.8351924e-33]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.8356125e-33]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.8358366e-33]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.8361168e-33]\n",
      "[True, False]\n",
      "[9.9999994e-01 4.5572551e-36]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.8367053e-33]\n",
      "[True, False]\n",
      "[9.9999994e-01 4.5582983e-36]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.8372659e-33]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4473139e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4470821e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4468281e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4465633e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4463204e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4460777e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4458350e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4455923e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4453387e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4450851e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4448426e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4446000e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4443466e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4441152e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4438728e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4436085e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.5050488e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.5049224e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.5046583e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.5043943e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.5041534e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.5037632e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.5035109e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.5032470e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.5029832e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.5028113e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.5025476e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.5022839e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.5020204e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.5017797e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4877640e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4875030e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4872534e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4869925e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4867428e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4864934e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4862325e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4859830e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4857110e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4854049e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4851330e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4848724e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4847591e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4844987e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4842608e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4838645e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4837400e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.4834797e-29]\n",
      "[True, False]\n",
      "[9.9999994e-01 4.5857851e-36]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.8515909e-33]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.8519017e-33]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.8521561e-33]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.8524671e-33]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.8527497e-33]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.8530324e-33]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.8533294e-33]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.8536262e-33]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.8539234e-33]\n",
      "[True, False]\n",
      "[9.9999994e-01 4.5912464e-36]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.8544891e-33]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.8547580e-33]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.8550976e-33]\n",
      "[True, False]\n",
      "[9.9999994e-01 1.8554091e-33]\n",
      "[True, False]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 ... 2 2 2]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [821147, 100]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9637/507168843.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Multi classification metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'DDoS'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'DoS'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Unknown'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttackClassificationModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Print results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DeepLearningSecurity/FinalProject/AttackClassification/AttackClassificationModel.ipynb\u001b[0m in \u001b[0;36mget_scores\u001b[0;34m(Y_test, Y_pred, labels)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    332\u001b[0m         raise ValueError(\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [821147, 100]"
     ]
    }
   ],
   "source": [
    "nadam = optimizers.Nadam(learning_rate = learning_rate, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08, schedule_decay = 0.004)\n",
    "cnn_model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"nadam\", metrics = [\"accuracy\"])\n",
    "\n",
    "for i in range(1):\n",
    "    print(\"Iteration \" + str(i))\n",
    "    \n",
    "    # Train\n",
    "    cnn_model, train_time = AttackClassificationModel.train(X_train, Y_train, X_val, Y_val, epochs, batch_size, reduce_lr, cnn_model)\n",
    "    \n",
    "    # Test\n",
    "    Y_pred, test_time = AttackClassificationModel.test(X_test, cnn_model)\n",
    "    print(Y_pred)\n",
    "    print(Y_test)\n",
    "    \n",
    "    # Multi classification metrics\n",
    "    labels = ['DDoS', 'DoS', 'Unknown']\n",
    "    acc, f1, pre, rec = AttackClassificationModel.get_scores(Y_test, Y_pred, labels)\n",
    "    \n",
    "    # Print results\n",
    "    AttackClassificationModel.print_results(learning_rate,\n",
    "                                            epochs,\n",
    "                                            batch_size,\n",
    "                                            X_train,\n",
    "                                            X_val,\n",
    "                                            X_test,\n",
    "                                            opt_time,\n",
    "                                            train_time,\n",
    "                                            test_time,\n",
    "                                            acc,\n",
    "                                            f1,\n",
    "                                            pre,\n",
    "                                            rec,\n",
    "                                            Y_test,\n",
    "                                            Y_pred,\n",
    "                                            \"CNN\",\n",
    "                                            \"Results/botiot.txt\")\n",
    "    \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cd1483",
   "metadata": {},
   "source": [
    "# Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1ba710",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Model\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "for i in range(1):\n",
    "    print(\"Iteration \" + str(i))\n",
    "    \n",
    "    # Train\n",
    "    nb_model, train_time = AttackClassificationModel.train_nb_knn(X_train, Y_train, X_val, nb_model)\n",
    "    \n",
    "    # Test\n",
    "    Y_pred, test_time = AttackClassificationModel.test(X_test, nb_model)\n",
    "    \n",
    "    # Multi classification metrics\n",
    "    labels = ['DDoS', 'DoS', 'Unknown']\n",
    "    acc, f1, pre, rec = AttackClassificationModel.get_scores(Y_test, Y_pred, labels)\n",
    "    \n",
    "    # Print results\n",
    "    AttackClassificationModel.print_results(learning_rate,\n",
    "                                            epochs,\n",
    "                                            batch_size,\n",
    "                                            X_train,\n",
    "                                            X_val,\n",
    "                                            X_test,\n",
    "                                            opt_time,\n",
    "                                            train_time,\n",
    "                                            test_time,\n",
    "                                            acc,\n",
    "                                            f1,\n",
    "                                            pre,\n",
    "                                            rec,\n",
    "                                            Y_test,\n",
    "                                            Y_pred,\n",
    "                                            \"NB\",\n",
    "                                            \"Results/botiot.txt)\n",
    "    \n",
    "    print(\"\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857f74c5",
   "metadata": {},
   "source": [
    "# KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1147810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Model\n",
    "knn_model = KNeighborsClassifier(n_neighbors = 50)\n",
    "\n",
    "for i in range(1):\n",
    "    print(\"Iteration \" + str(i))\n",
    "    \n",
    "    # Train\n",
    "    knn_model, train_time = AttackClassificationModel.train_nb_knn(X_train, Y_train, X_val, knn_model)\n",
    "    \n",
    "    # Test\n",
    "    Y_pred, test_time = AttackClassificationModel.test(X_test, knn_model)\n",
    "    \n",
    "    # Multi classification metrics\n",
    "    labels = ['DDoS', 'DoS', 'Unknown']\n",
    "    acc, f1, pre, rec = AttackClassificationModel.get_scores(Y_test, Y_pred, labels)\n",
    "    \n",
    "    # Print results\n",
    "    AttackClassificationModel.print_results(learning_rate,\n",
    "                                            epochs,\n",
    "                                            batch_size,\n",
    "                                            X_train,\n",
    "                                            X_val,\n",
    "                                            X_test,\n",
    "                                            opt_time,\n",
    "                                            train_time,\n",
    "                                            test_time,\n",
    "                                            acc,\n",
    "                                            f1,\n",
    "                                            pre,\n",
    "                                            rec,\n",
    "                                            Y_test,\n",
    "                                            Y_pred,\n",
    "                                            \"NB\",\n",
    "                                            \"Results/botiot.txt)\n",
    "    \n",
    "    print(\"\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702d8d87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
