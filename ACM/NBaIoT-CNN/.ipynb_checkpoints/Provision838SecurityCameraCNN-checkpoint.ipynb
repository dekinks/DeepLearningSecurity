{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b17c252e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/andressa.amaral/.local/lib/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in /home/andressa.amaral/.local/lib/python3.7/site-packages (0.11.2)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from seaborn) (3.5.1)\n",
      "Requirement already satisfied: pandas>=0.23 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from seaborn) (1.3.5)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from seaborn) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from seaborn) (1.21.5)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (3.0.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (4.31.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (1.4.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (9.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pandas>=0.23->seaborn) (2022.1)\n",
      "Requirement already satisfied: typing-extensions in /home/andressa.amaral/.local/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=2.2->seaborn) (4.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow-gpu in /home/andressa.amaral/.local/lib/python3.7/site-packages (2.9.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.44.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (3.19.4)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (2.9.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (0.24.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (13.0.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (3.6.0)\n",
      "Requirement already satisfied: packaging in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (21.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (2.9.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.21.5)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.14.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (2.9.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.0.0)\n",
      "Requirement already satisfied: setuptools in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (60.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.12)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (4.1.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.30.0)\n",
      "Requirement already satisfied: cached-property in /home/andressa.amaral/.local/lib/python3.7/site-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (2.27.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (2.6.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (0.4.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from packaging->tensorflow-gpu) (3.0.7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (5.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.11.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (1.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (2018.1.18)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bayesian-optimization in /home/andressa.amaral/.local/lib/python3.7/site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from bayesian-optimization) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from bayesian-optimization) (1.0.2)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from bayesian-optimization) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-20 15:52:53.703604: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-20 15:52:53.703638: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas\n",
    "!pip3 install seaborn\n",
    "!pip3 install --upgrade tensorflow-gpu\n",
    "!pip3 install bayesian-optimization\n",
    "\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.layers import Lambda, Input, Dense, Dropout, Conv1D, MaxPooling1D, Flatten, GlobalAveragePooling1D, BatchNormalization\n",
    "from tensorflow.keras.losses import mse\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, mean_squared_error, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64862836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-20 15:52:55.814614: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-20 15:52:55.845037: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-20 15:52:55.845148: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-08-20 15:52:55.845351: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-08-20 15:52:55.847621: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-08-20 15:52:55.847700: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-08-20 15:52:55.847761: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-08-20 15:52:55.847771: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction = 0.333)\n",
    "sess = tf.compat.v1.Session(config = tf.compat.v1.ConfigProto(gpu_options = gpu_options))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f76368e",
   "metadata": {},
   "source": [
    "# P838 Security Camera Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "771d9155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benign traffic\n",
    "\n",
    "p8_benign = pd.read_csv('../nbaiot/Provision_PT_838_Security_Camera/benign_traffic.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p8_benign = p8_benign.copy(deep=True)\n",
    "\n",
    "columns = list(df_p8_benign.columns)\n",
    "chosen_columns = []\n",
    "for column in columns:\n",
    "    if column.find('L5') != -1:\n",
    "        chosen_columns.append(column)\n",
    "\n",
    "df_p8_benign = pd.DataFrame(df_p8_benign, columns = chosen_columns)\n",
    "\n",
    "# Mirai\n",
    "\n",
    "p8_mirai_ack = pd.read_csv('../nbaiot/Provision_PT_838_Security_Camera/mirai/ack.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p8_mirai_ack = p8_mirai_ack.copy(deep=True)\n",
    "df_p8_mirai_ack = pd.DataFrame(df_p8_mirai_ack, columns = chosen_columns)\n",
    "df_p8_mirai_ack = df_p8_mirai_ack.sample(frac=1)\n",
    "\n",
    "p8_mirai_scan = pd.read_csv('../nbaiot/Provision_PT_838_Security_Camera/mirai/scan.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p8_mirai_scan = p8_mirai_scan.copy(deep=True)\n",
    "df_p8_mirai_scan = pd.DataFrame(df_p8_mirai_scan, columns = chosen_columns)\n",
    "df_p8_mirai_scan = df_p8_mirai_scan.sample(frac=1)\n",
    "\n",
    "p8_mirai_syn = pd.read_csv('../nbaiot/Provision_PT_838_Security_Camera/mirai/syn.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p8_mirai_syn = p8_mirai_syn.copy(deep=True)\n",
    "df_p8_mirai_syn = pd.DataFrame(df_p8_mirai_syn, columns = chosen_columns)\n",
    "df_p8_mirai_syn = df_p8_mirai_syn.sample(frac=1)\n",
    "\n",
    "p8_mirai_udp = pd.read_csv('../nbaiot/Provision_PT_838_Security_Camera/mirai/udp.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p8_mirai_udp = p8_mirai_udp.copy(deep=True)\n",
    "df_p8_mirai_udp = pd.DataFrame(df_p8_mirai_udp, columns = chosen_columns)\n",
    "df_p8_mirai_udp = df_p8_mirai_udp.sample(frac=1)\n",
    "\n",
    "p8_mirai_udpplain = pd.read_csv('../nbaiot/Provision_PT_838_Security_Camera/mirai/udpplain.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p8_mirai_udpplain = p8_mirai_udpplain.copy(deep=True)\n",
    "df_p8_mirai_udpplain = pd.DataFrame(df_p8_mirai_udpplain, columns = chosen_columns)\n",
    "df_p8_mirai_udpplain = df_p8_mirai_udpplain.sample(frac=1)\n",
    "\n",
    "# Bashlite\n",
    "\n",
    "p8_bashlite_combo = pd.read_csv('../nbaiot/Provision_PT_838_Security_Camera/gafgyt/combo.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p8_bashlite_combo = p8_bashlite_combo.copy(deep=True)\n",
    "df_p8_bashlite_combo = pd.DataFrame(df_p8_bashlite_combo, columns = chosen_columns)\n",
    "df_p8_bashlite_combo = df_p8_bashlite_combo.sample(frac=1)\n",
    "\n",
    "p8_bashlite_junk = pd.read_csv('../nbaiot/Provision_PT_838_Security_Camera/gafgyt/junk.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p8_bashlite_junk = p8_bashlite_junk.copy(deep=True)\n",
    "df_p8_bashlite_junk = pd.DataFrame(df_p8_bashlite_junk, columns = chosen_columns)\n",
    "df_p8_bashlite_junk = df_p8_bashlite_junk.sample(frac=1)\n",
    "\n",
    "p8_bashlite_scan = pd.read_csv('../nbaiot/Provision_PT_838_Security_Camera/gafgyt/scan.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p8_bashlite_scan = p8_bashlite_scan.copy(deep=True)\n",
    "df_p8_bashlite_scan = pd.DataFrame(df_p8_bashlite_scan, columns = chosen_columns)\n",
    "df_p8_bashlite_scan = df_p8_bashlite_scan.sample(frac=1)\n",
    "\n",
    "p8_bashlite_udp = pd.read_csv('../nbaiot/Provision_PT_838_Security_Camera/gafgyt/udp.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p8_bashlite_udp = p8_bashlite_udp.copy(deep=True)\n",
    "df_p8_bashlite_udp = pd.DataFrame(df_p8_bashlite_udp, columns = chosen_columns)\n",
    "df_p8_bashlite_udp = df_p8_bashlite_udp.sample(frac=1)\n",
    "\n",
    "p8_bashlite_tcp = pd.read_csv('../nbaiot/Provision_PT_838_Security_Camera/gafgyt/tcp.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p8_bashlite_tcp = p8_bashlite_tcp.copy(deep=True)\n",
    "df_p8_bashlite_tcp = pd.DataFrame(df_p8_bashlite_tcp, columns = chosen_columns)\n",
    "df_p8_bashlite_tcp = df_p8_bashlite_tcp.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7fe73d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing information\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_p8_miraiack_norm = scaler.fit_transform(df_p8_mirai_ack)\n",
    "df_p8_miraiscan_norm = scaler.fit_transform(df_p8_mirai_scan)\n",
    "df_p8_miraisyn_norm = scaler.fit_transform(df_p8_mirai_syn)\n",
    "df_p8_miraiudp_norm = scaler.fit_transform(df_p8_mirai_udp)\n",
    "df_p8_miraiudpplain_norm = scaler.fit_transform(df_p8_mirai_udpplain)\n",
    "\n",
    "df_p8_bashlitecombo_norm = scaler.fit_transform(df_p8_bashlite_combo)\n",
    "df_p8_bashlitejunk_norm = scaler.fit_transform(df_p8_bashlite_junk)\n",
    "df_p8_bashlitescan_norm = scaler.fit_transform(df_p8_bashlite_scan)\n",
    "df_p8_bashliteudp_norm = scaler.fit_transform(df_p8_bashlite_udp)\n",
    "df_p8_bashlitetcp_norm = scaler.fit_transform(df_p8_bashlite_tcp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01bc756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mirai attack labelization\n",
    "\n",
    "label_mirai_ack = list(np.full(df_p8_miraiack_norm.shape[0], 0))\n",
    "miraiack_norm = pd.DataFrame(df_p8_miraiack_norm)\n",
    "miraiack_norm['Label'] = label_mirai_ack\n",
    "\n",
    "label_mirai_scan = list(np.full(df_p8_miraiscan_norm.shape[0], 1))\n",
    "miraiscan_norm = pd.DataFrame(df_p8_miraiscan_norm)\n",
    "miraiscan_norm['Label'] = label_mirai_scan\n",
    "\n",
    "label_mirai_syn = list(np.full(df_p8_miraisyn_norm.shape[0], 2))\n",
    "miraisyn_norm = pd.DataFrame(df_p8_miraisyn_norm)\n",
    "miraisyn_norm['Label'] = label_mirai_syn\n",
    "\n",
    "label_mirai_udp = list(np.full(df_p8_miraiudp_norm.shape[0], 3))\n",
    "miraiudp_norm = pd.DataFrame(df_p8_miraiudp_norm)\n",
    "miraiudp_norm['Label'] = label_mirai_udp\n",
    "\n",
    "label_mirai_udpplain = list(np.full(df_p8_miraiudpplain_norm.shape[0], 4))\n",
    "miraiudpplain_norm = pd.DataFrame(df_p8_miraiudpplain_norm)\n",
    "miraiudpplain_norm['Label'] = label_mirai_udpplain\n",
    "\n",
    "# Bashlite attack labelization\n",
    "\n",
    "label_bashlite_combo = list(np.full(df_p8_bashlitecombo_norm.shape[0], 5))\n",
    "bashlitecombo_norm = pd.DataFrame(df_p8_bashlitecombo_norm)\n",
    "bashlitecombo_norm['Label'] = label_bashlite_combo\n",
    "\n",
    "label_bashlite_junk = list(np.full(df_p8_bashlitejunk_norm.shape[0], 6))\n",
    "bashlitejunk_norm = pd.DataFrame(df_p8_bashlitejunk_norm)\n",
    "bashlitejunk_norm['Label'] = label_bashlite_junk\n",
    "\n",
    "label_bashlite_scan = list(np.full(df_p8_bashlitescan_norm.shape[0], 7))\n",
    "bashlitescan_norm = pd.DataFrame(df_p8_bashlitescan_norm)\n",
    "bashlitescan_norm['Label'] = label_bashlite_scan\n",
    "\n",
    "label_bashlite_udp = list(np.full(df_p8_bashliteudp_norm.shape[0], 8))\n",
    "bashliteudp_norm = pd.DataFrame(df_p8_bashliteudp_norm)\n",
    "bashliteudp_norm['Label'] = label_bashlite_udp\n",
    "\n",
    "label_bashlite_tcp = list(np.full(df_p8_bashlitetcp_norm.shape[0], 9))\n",
    "bashlitetcp_norm = pd.DataFrame(df_p8_bashlitetcp_norm)\n",
    "bashlitetcp_norm['Label'] = label_bashlite_tcp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c755fbe7",
   "metadata": {},
   "source": [
    "# CNN - Attack Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8be374",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b13a59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 43\n",
    "number_features = 23\n",
    "learning_rate = 0.05\n",
    "epochs = 50\n",
    "\n",
    "dict_params = { 'learning_rate': learning_rate, 'batch_size': int(32 * batch_size), 'epochs': int(epochs) }\n",
    "pbounds = { 'learning_rate': (0.000001, 0.1), 'batch_size': (1, 4.001), 'epochs': (1, 100) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ce8adf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516858\n"
     ]
    }
   ],
   "source": [
    "# Train set\n",
    "\n",
    "len_mirai_ack_train = int(0.7 * len(miraiack_norm))\n",
    "X_train_mirai_ack = miraiack_norm[:len_mirai_ack_train]\n",
    "\n",
    "len_mirai_scan_train = int(0.7 * len(miraiscan_norm))\n",
    "X_train_mirai_scan = miraiscan_norm[:len_mirai_scan_train]\n",
    "\n",
    "len_mirai_syn_train = int(0.7 * len(miraisyn_norm))\n",
    "X_train_mirai_syn = miraisyn_norm[:len_mirai_syn_train]\n",
    "\n",
    "len_mirai_udp_train = int(0.7 * len(miraiudp_norm))\n",
    "X_train_mirai_udp = miraiudp_norm[:len_mirai_udp_train]\n",
    "\n",
    "len_mirai_udpplain_train = int(0.7 * len(miraiudpplain_norm))\n",
    "X_train_mirai_udpplain = miraiudpplain_norm[:len_mirai_udpplain_train]\n",
    "\n",
    "len_bashlite_combo_train = int(0.7 * len(bashlitecombo_norm))\n",
    "X_train_bashlite_combo = bashlitecombo_norm[:len_bashlite_combo_train]\n",
    "\n",
    "len_bashlite_junk_train = int(0.7 * len(bashlitejunk_norm))\n",
    "X_train_bashlite_junk = bashlitejunk_norm[:len_bashlite_junk_train]\n",
    "\n",
    "len_bashlite_scan_train = int(0.7 * len(bashlitescan_norm))\n",
    "X_train_bashlite_scan = bashlitescan_norm[:len_bashlite_scan_train]\n",
    "\n",
    "len_bashlite_udp_train = int(0.7 * len(bashliteudp_norm))\n",
    "X_train_bashlite_udp = bashliteudp_norm[:len_bashlite_udp_train]\n",
    "\n",
    "len_bashlite_tcp_train = int(0.7 * len(bashlitetcp_norm))\n",
    "X_train_bashlite_tcp = bashlitetcp_norm[:len_bashlite_tcp_train]\n",
    "\n",
    "np_train = np.concatenate([X_train_mirai_ack, X_train_mirai_scan, X_train_mirai_syn, X_train_mirai_udp, X_train_mirai_udpplain,\n",
    "                          X_train_bashlite_combo, X_train_bashlite_junk, X_train_bashlite_scan, X_train_bashlite_udp,\n",
    "                          X_train_bashlite_tcp])\n",
    "\n",
    "df_train = pd.DataFrame(np_train)\n",
    "label_train = df_train.pop(number_features)\n",
    "\n",
    "X_train = df_train.to_numpy()\n",
    "Y_train = label_train.to_numpy()\n",
    "\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b16726f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110752\n"
     ]
    }
   ],
   "source": [
    "# Test set\n",
    "\n",
    "len_mirai_ack_test = len_mirai_ack_train + int(0.15 * len(miraiack_norm))\n",
    "X_test_mirai_ack = miraiack_norm[len_mirai_ack_train : len_mirai_ack_test]\n",
    "\n",
    "len_mirai_scan_test = len_mirai_scan_train + int(0.15 * len(miraiscan_norm))\n",
    "X_test_mirai_scan = miraiscan_norm[len_mirai_scan_train : len_mirai_scan_test]\n",
    "\n",
    "len_mirai_syn_test = len_mirai_syn_train + int(0.15 * len(miraisyn_norm))\n",
    "X_test_mirai_syn = miraisyn_norm[len_mirai_syn_train : len_mirai_syn_test]\n",
    "\n",
    "len_mirai_udp_test = len_mirai_udp_train + int(0.15 * len(miraiudp_norm))\n",
    "X_test_mirai_udp = miraiudp_norm[len_mirai_udp_train : len_mirai_udp_test]\n",
    "\n",
    "len_mirai_udpplain_test = len_mirai_udpplain_train + int(0.15 * len(miraiudpplain_norm))\n",
    "X_test_mirai_udpplain = miraiudpplain_norm[len_mirai_udpplain_train : len_mirai_udpplain_test]\n",
    "\n",
    "len_bashlite_combo_test = len_bashlite_combo_train + int(0.15 * len(bashlitecombo_norm))\n",
    "X_test_bashlite_combo = bashlitecombo_norm[len_bashlite_combo_train : len_bashlite_combo_test]\n",
    "\n",
    "len_bashlite_junk_test = len_bashlite_junk_train + int(0.15 * len(bashlitejunk_norm))\n",
    "X_test_bashlite_junk = bashlitejunk_norm[len_bashlite_junk_train : len_bashlite_junk_test]\n",
    "\n",
    "len_bashlite_scan_test = len_bashlite_scan_train + int(0.15 * len(bashlitescan_norm))\n",
    "X_test_bashlite_scan = bashlitescan_norm[len_bashlite_scan_train : len_bashlite_scan_test]\n",
    "\n",
    "len_bashlite_udp_test = len_bashlite_udp_train + int(0.15 * len(bashliteudp_norm))\n",
    "X_test_bashlite_udp = bashliteudp_norm[len_bashlite_udp_train : len_bashlite_udp_test]\n",
    "\n",
    "len_bashlite_tcp_test = len_bashlite_tcp_train + int(0.15 * len(bashlitetcp_norm))\n",
    "X_test_bashlite_tcp = bashlitetcp_norm[len_bashlite_tcp_train : len_bashlite_tcp_test]\n",
    "\n",
    "np_test = np.concatenate([X_test_mirai_ack, X_test_mirai_scan, X_test_mirai_syn, X_test_mirai_udp, X_test_mirai_udpplain,\n",
    "                          X_test_bashlite_combo, X_test_bashlite_junk, X_test_bashlite_scan, X_test_bashlite_udp,\n",
    "                          X_test_bashlite_tcp])\n",
    "\n",
    "df_test = pd.DataFrame(np_test)\n",
    "label_test = df_test.pop(number_features)\n",
    "\n",
    "X_test = df_test.to_numpy()\n",
    "Y_test = label_test.to_numpy()\n",
    "\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5735be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set\n",
    "\n",
    "X_val_mirai_ack = miraiack_norm[len_mirai_ack_test:]\n",
    "X_val_mirai_scan = miraiscan_norm[len_mirai_scan_test:]\n",
    "X_val_mirai_syn = miraisyn_norm[len_mirai_syn_test:]\n",
    "X_val_mirai_udp = miraiudp_norm[len_mirai_udp_test:]\n",
    "X_val_mirai_udpplain = miraiudpplain_norm[len_mirai_udpplain_test:]\n",
    "\n",
    "X_val_bashlite_combo = bashlitecombo_norm[len_bashlite_combo_test:]\n",
    "X_val_bashlite_junk = bashlitejunk_norm[len_bashlite_junk_test:]\n",
    "X_val_bashlite_scan = bashlitescan_norm[len_bashlite_scan_test:]\n",
    "X_val_bashlite_udp = bashlitetcp_norm[len_bashlite_udp_test:]\n",
    "X_val_bashlite_tcp = bashlitetcp_norm[len_bashlite_tcp_test:]\n",
    "\n",
    "np_val = np.concatenate([X_val_mirai_ack, X_val_mirai_scan, X_val_mirai_syn, X_val_mirai_udp, X_val_mirai_udpplain,\n",
    "                          X_val_bashlite_combo, X_val_bashlite_junk, X_val_bashlite_scan, X_val_bashlite_udp,\n",
    "                          X_val_bashlite_tcp])\n",
    "\n",
    "df_val = pd.DataFrame(np_val)\n",
    "label_val = df_val.pop(number_features)\n",
    "\n",
    "X_val = df_val.to_numpy()\n",
    "Y_val = label_val.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3bb7211",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_CNN = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_CNN = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "X_val_CNN = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n",
    "\n",
    "Y_train_CNN = Y_train\n",
    "Y_test_CNN = Y_test\n",
    "Y_val_CNN = Y_val\n",
    "\n",
    "samples, feature, depth = X_train_CNN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6cf8937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model with 1D convolutional layer\n",
    "\n",
    "def CNN():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv1D(32, 3, activation='relu', padding = 'same', kernel_initializer = 'he_uniform', input_shape=(feature, depth)))\n",
    "    model.add(layers.MaxPooling1D(pool_size = 2, strides = 2))\n",
    "    model.add(layers.Conv1D(64, 3, activation='relu', padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "    model.add(layers.MaxPooling1D(pool_size = 2, strides = 2))\n",
    "    model.add(layers.Conv1D(64, 3, activation='relu', padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84cde696",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(moniter = 'val_loss', factor = 0.1, patience = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adda2e43",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cf65980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training step with Bayesian optimization\n",
    "\n",
    "def training(X_train = X_train_CNN,\n",
    "             Y_train = Y_train_CNN, \n",
    "             X_val = X_val_CNN, \n",
    "             Y_val = Y_val_CNN, \n",
    "             X_test = X_test_CNN, \n",
    "             Y_test = Y_test_CNN, \n",
    "             learning_rate = learning_rate, \n",
    "             epochs = epochs, \n",
    "             batch_size = batch_size,\n",
    "             reduce_lr = reduce_lr):\n",
    "    \n",
    "    nadam = optimizers.Nadam(learning_rate = dict_params['learning_rate'], beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08, schedule_decay = 0.004)\n",
    "    \n",
    "    model = CNN()\n",
    "    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"nadam\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    history = model.fit(X_train, Y_train, \n",
    "                        epochs = dict_params['epochs'], \n",
    "                        batch_size = dict_params['batch_size'], \n",
    "                        validation_data = (X_val, Y_val),\n",
    "                        callbacks = [reduce_lr])\n",
    "    \n",
    "    scores = model.evaluate(X_test, Y_test)\n",
    "    \n",
    "    print('loss:', scores[0])\n",
    "    print('accuracy:', scores[1])\n",
    "    return scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17af310d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Bayesian optimization to choose the best hyperparameters\\n\\noptimizer = BayesianOptimization(\\n    f = training,\\n    pbounds = pbounds,\\n    verbose = 2, \\n    random_state = 1,\\n)\\n\\ntrain_start = time.time()\\n\\noptimizer.maximize(init_points = 5, n_iter = 5)\\n\\ntrain_end = time.time()\\ntrain_time = train_end - train_start\\nprint(\"Training time:\", train_time)\\n\\nprint(optimizer.max)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Bayesian optimization to choose the best hyperparameters\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f = training,\n",
    "    pbounds = pbounds,\n",
    "    verbose = 2, \n",
    "    random_state = 1,\n",
    ")\n",
    "\n",
    "train_start = time.time()\n",
    "\n",
    "optimizer.maximize(init_points = 5, n_iter = 5)\n",
    "\n",
    "train_end = time.time()\n",
    "train_time = train_end - train_start\n",
    "print(\"Training time:\", train_time)\n",
    "\n",
    "print(optimizer.max)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0a990c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 516858 samples, validate on 95496 samples\n",
      "Epoch 1/73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-20 15:53:23.271680: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-08-20 15:53:23.303479: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516716/516858 [============================>.] - ETA: 0s - loss: 0.3077 - accuracy: 0.8783"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andressa.amaral/.local/lib/python3.7/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516858/516858 [==============================] - 34s 66us/sample - loss: 0.3076 - accuracy: 0.8783 - val_loss: 0.3221 - val_accuracy: 0.8676 - lr: 0.0010\n",
      "Epoch 2/73\n",
      "516858/516858 [==============================] - 34s 66us/sample - loss: 0.2754 - accuracy: 0.8877 - val_loss: 0.3263 - val_accuracy: 0.8664 - lr: 0.0010\n",
      "Epoch 3/73\n",
      "516858/516858 [==============================] - 35s 67us/sample - loss: 0.2711 - accuracy: 0.8888 - val_loss: 0.3176 - val_accuracy: 0.8701 - lr: 0.0010\n",
      "Epoch 4/73\n",
      "516858/516858 [==============================] - 34s 67us/sample - loss: 0.2681 - accuracy: 0.8897 - val_loss: 0.3109 - val_accuracy: 0.8704 - lr: 0.0010\n",
      "Epoch 5/73\n",
      "516858/516858 [==============================] - 34s 66us/sample - loss: 0.2658 - accuracy: 0.8902 - val_loss: 0.3091 - val_accuracy: 0.8718 - lr: 0.0010\n",
      "Epoch 6/73\n",
      "516858/516858 [==============================] - 35s 67us/sample - loss: 0.2642 - accuracy: 0.8909 - val_loss: 0.3085 - val_accuracy: 0.8727 - lr: 0.0010\n",
      "Epoch 7/73\n",
      "516858/516858 [==============================] - 34s 66us/sample - loss: 0.2626 - accuracy: 0.8914 - val_loss: 0.3066 - val_accuracy: 0.8723 - lr: 0.0010\n",
      "Epoch 8/73\n",
      "516858/516858 [==============================] - 34s 66us/sample - loss: 0.2604 - accuracy: 0.8920 - val_loss: 0.3097 - val_accuracy: 0.8689 - lr: 0.0010\n",
      "Epoch 9/73\n",
      "516858/516858 [==============================] - 34s 66us/sample - loss: 0.2559 - accuracy: 0.8938 - val_loss: 0.3026 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 10/73\n",
      "516858/516858 [==============================] - 35s 68us/sample - loss: 0.2461 - accuracy: 0.8988 - val_loss: 0.2782 - val_accuracy: 0.8843 - lr: 0.0010\n",
      "Epoch 11/73\n",
      "516858/516858 [==============================] - 35s 68us/sample - loss: 0.2341 - accuracy: 0.9041 - val_loss: 0.2642 - val_accuracy: 0.8919 - lr: 0.0010\n",
      "Epoch 12/73\n",
      "516858/516858 [==============================] - 35s 69us/sample - loss: 0.2257 - accuracy: 0.9070 - val_loss: 0.2500 - val_accuracy: 0.9002 - lr: 0.0010\n",
      "Epoch 13/73\n",
      "516858/516858 [==============================] - 36s 69us/sample - loss: 0.2206 - accuracy: 0.9091 - val_loss: 0.2891 - val_accuracy: 0.8728 - lr: 0.0010\n",
      "Epoch 14/73\n",
      "516858/516858 [==============================] - 35s 69us/sample - loss: 0.2177 - accuracy: 0.9102 - val_loss: 0.2448 - val_accuracy: 0.8977 - lr: 0.0010\n",
      "Epoch 15/73\n",
      "516858/516858 [==============================] - 36s 69us/sample - loss: 0.2150 - accuracy: 0.9112 - val_loss: 0.2401 - val_accuracy: 0.8998 - lr: 0.0010\n",
      "Epoch 16/73\n",
      "516858/516858 [==============================] - 36s 69us/sample - loss: 0.2121 - accuracy: 0.9123 - val_loss: 0.2364 - val_accuracy: 0.9028 - lr: 0.0010\n",
      "Epoch 17/73\n",
      "516858/516858 [==============================] - 35s 69us/sample - loss: 0.2113 - accuracy: 0.9127 - val_loss: 0.2590 - val_accuracy: 0.8949 - lr: 0.0010\n",
      "Epoch 18/73\n",
      "516858/516858 [==============================] - 36s 69us/sample - loss: 0.2087 - accuracy: 0.9136 - val_loss: 0.2371 - val_accuracy: 0.9013 - lr: 0.0010\n",
      "Epoch 19/73\n",
      "516858/516858 [==============================] - 35s 67us/sample - loss: 0.2079 - accuracy: 0.9141 - val_loss: 0.2338 - val_accuracy: 0.9024 - lr: 0.0010\n",
      "Epoch 20/73\n",
      "516858/516858 [==============================] - 35s 67us/sample - loss: 0.2059 - accuracy: 0.9146 - val_loss: 0.2530 - val_accuracy: 0.8925 - lr: 0.0010\n",
      "Epoch 21/73\n",
      "516858/516858 [==============================] - 35s 69us/sample - loss: 0.2051 - accuracy: 0.9148 - val_loss: 0.2316 - val_accuracy: 0.9042 - lr: 0.0010\n",
      "Epoch 22/73\n",
      "516858/516858 [==============================] - 36s 70us/sample - loss: 0.2037 - accuracy: 0.9158 - val_loss: 0.2397 - val_accuracy: 0.9009 - lr: 0.0010\n",
      "Epoch 23/73\n",
      "516858/516858 [==============================] - 37s 72us/sample - loss: 0.2032 - accuracy: 0.9160 - val_loss: 0.3619 - val_accuracy: 0.8749 - lr: 0.0010\n",
      "Epoch 24/73\n",
      "516858/516858 [==============================] - 41s 80us/sample - loss: 0.2018 - accuracy: 0.9163 - val_loss: 0.2303 - val_accuracy: 0.9043 - lr: 0.0010\n",
      "Epoch 25/73\n",
      "516858/516858 [==============================] - 40s 77us/sample - loss: 0.2008 - accuracy: 0.9165 - val_loss: 0.2223 - val_accuracy: 0.9069 - lr: 0.0010\n",
      "Epoch 26/73\n",
      "516858/516858 [==============================] - 41s 79us/sample - loss: 0.2010 - accuracy: 0.9165 - val_loss: 0.2233 - val_accuracy: 0.9072 - lr: 0.0010\n",
      "Epoch 27/73\n",
      "516858/516858 [==============================] - 40s 78us/sample - loss: 0.1993 - accuracy: 0.9172 - val_loss: 0.2245 - val_accuracy: 0.9057 - lr: 0.0010\n",
      "Epoch 28/73\n",
      "516858/516858 [==============================] - 40s 78us/sample - loss: 0.1992 - accuracy: 0.9173 - val_loss: 0.2519 - val_accuracy: 0.8982 - lr: 0.0010\n",
      "Epoch 29/73\n",
      "516858/516858 [==============================] - 38s 73us/sample - loss: 0.1985 - accuracy: 0.9177 - val_loss: 0.2312 - val_accuracy: 0.9028 - lr: 0.0010\n",
      "Epoch 30/73\n",
      "516858/516858 [==============================] - 36s 69us/sample - loss: 0.1977 - accuracy: 0.9178 - val_loss: 0.2245 - val_accuracy: 0.9066 - lr: 0.0010\n",
      "Epoch 31/73\n",
      "516858/516858 [==============================] - 36s 69us/sample - loss: 0.1983 - accuracy: 0.9180 - val_loss: 0.2261 - val_accuracy: 0.9050 - lr: 0.0010\n",
      "Epoch 32/73\n",
      "516858/516858 [==============================] - 36s 69us/sample - loss: 0.1967 - accuracy: 0.9183 - val_loss: 0.2284 - val_accuracy: 0.9050 - lr: 0.0010\n",
      "Epoch 33/73\n",
      "516858/516858 [==============================] - 35s 68us/sample - loss: 0.1970 - accuracy: 0.9181 - val_loss: 0.2360 - val_accuracy: 0.9027 - lr: 0.0010\n",
      "Epoch 34/73\n",
      "516858/516858 [==============================] - 38s 73us/sample - loss: 0.1964 - accuracy: 0.9185 - val_loss: 0.2405 - val_accuracy: 0.8992 - lr: 0.0010\n",
      "Epoch 35/73\n",
      "516858/516858 [==============================] - 37s 72us/sample - loss: 0.1956 - accuracy: 0.9187 - val_loss: 0.2251 - val_accuracy: 0.9057 - lr: 0.0010\n",
      "Epoch 36/73\n",
      "516858/516858 [==============================] - 38s 73us/sample - loss: 0.1786 - accuracy: 0.9252 - val_loss: 0.2080 - val_accuracy: 0.9126 - lr: 1.0000e-04\n",
      "Epoch 37/73\n",
      "516858/516858 [==============================] - 38s 73us/sample - loss: 0.1765 - accuracy: 0.9258 - val_loss: 0.2083 - val_accuracy: 0.9139 - lr: 1.0000e-04\n",
      "Epoch 38/73\n",
      "516858/516858 [==============================] - 38s 74us/sample - loss: 0.1755 - accuracy: 0.9263 - val_loss: 0.2062 - val_accuracy: 0.9141 - lr: 1.0000e-04\n",
      "Epoch 39/73\n",
      "516858/516858 [==============================] - 38s 73us/sample - loss: 0.1749 - accuracy: 0.9264 - val_loss: 0.2048 - val_accuracy: 0.9135 - lr: 1.0000e-04\n",
      "Epoch 40/73\n",
      "516858/516858 [==============================] - 38s 73us/sample - loss: 0.1741 - accuracy: 0.9268 - val_loss: 0.2089 - val_accuracy: 0.9130 - lr: 1.0000e-04\n",
      "Epoch 41/73\n",
      "516858/516858 [==============================] - 38s 73us/sample - loss: 0.1737 - accuracy: 0.9268 - val_loss: 0.2061 - val_accuracy: 0.9132 - lr: 1.0000e-04\n",
      "Epoch 42/73\n",
      "516858/516858 [==============================] - 38s 74us/sample - loss: 0.1731 - accuracy: 0.9270 - val_loss: 0.2050 - val_accuracy: 0.9143 - lr: 1.0000e-04\n",
      "Epoch 43/73\n",
      "516858/516858 [==============================] - 38s 73us/sample - loss: 0.1727 - accuracy: 0.9271 - val_loss: 0.2030 - val_accuracy: 0.9149 - lr: 1.0000e-04\n",
      "Epoch 44/73\n",
      "516858/516858 [==============================] - 38s 73us/sample - loss: 0.1722 - accuracy: 0.9273 - val_loss: 0.2060 - val_accuracy: 0.9138 - lr: 1.0000e-04\n",
      "Epoch 45/73\n",
      "516858/516858 [==============================] - 37s 73us/sample - loss: 0.1718 - accuracy: 0.9277 - val_loss: 0.2014 - val_accuracy: 0.9153 - lr: 1.0000e-04\n",
      "Epoch 46/73\n",
      "516858/516858 [==============================] - 38s 74us/sample - loss: 0.1715 - accuracy: 0.9278 - val_loss: 0.2030 - val_accuracy: 0.9141 - lr: 1.0000e-04\n",
      "Epoch 47/73\n",
      "516858/516858 [==============================] - 36s 70us/sample - loss: 0.1710 - accuracy: 0.9279 - val_loss: 0.2014 - val_accuracy: 0.9154 - lr: 1.0000e-04\n",
      "Epoch 48/73\n",
      "516858/516858 [==============================] - 34s 67us/sample - loss: 0.1708 - accuracy: 0.9282 - val_loss: 0.2015 - val_accuracy: 0.9149 - lr: 1.0000e-04\n",
      "Epoch 49/73\n",
      "516858/516858 [==============================] - 35s 67us/sample - loss: 0.1706 - accuracy: 0.9282 - val_loss: 0.2044 - val_accuracy: 0.9140 - lr: 1.0000e-04\n",
      "Epoch 50/73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516858/516858 [==============================] - 34s 66us/sample - loss: 0.1702 - accuracy: 0.9282 - val_loss: 0.2013 - val_accuracy: 0.9160 - lr: 1.0000e-04\n",
      "Epoch 51/73\n",
      "516858/516858 [==============================] - 34s 66us/sample - loss: 0.1699 - accuracy: 0.9283 - val_loss: 0.2039 - val_accuracy: 0.9153 - lr: 1.0000e-04\n",
      "Epoch 52/73\n",
      "516858/516858 [==============================] - 34s 66us/sample - loss: 0.1695 - accuracy: 0.9284 - val_loss: 0.2056 - val_accuracy: 0.9145 - lr: 1.0000e-04\n",
      "Epoch 53/73\n",
      "516858/516858 [==============================] - 34s 66us/sample - loss: 0.1694 - accuracy: 0.9285 - val_loss: 0.2001 - val_accuracy: 0.9161 - lr: 1.0000e-04\n",
      "Epoch 54/73\n",
      "516858/516858 [==============================] - 34s 65us/sample - loss: 0.1691 - accuracy: 0.9286 - val_loss: 0.2011 - val_accuracy: 0.9154 - lr: 1.0000e-04\n",
      "Epoch 55/73\n",
      "516858/516858 [==============================] - 34s 66us/sample - loss: 0.1690 - accuracy: 0.9287 - val_loss: 0.1996 - val_accuracy: 0.9157 - lr: 1.0000e-04\n",
      "Epoch 56/73\n",
      "516858/516858 [==============================] - 35s 67us/sample - loss: 0.1687 - accuracy: 0.9286 - val_loss: 0.1999 - val_accuracy: 0.9161 - lr: 1.0000e-04\n",
      "Epoch 57/73\n",
      "516858/516858 [==============================] - 34s 65us/sample - loss: 0.1685 - accuracy: 0.9288 - val_loss: 0.2014 - val_accuracy: 0.9155 - lr: 1.0000e-04\n",
      "Epoch 58/73\n",
      "516858/516858 [==============================] - 34s 67us/sample - loss: 0.1682 - accuracy: 0.9290 - val_loss: 0.2004 - val_accuracy: 0.9162 - lr: 1.0000e-04\n",
      "Epoch 59/73\n",
      "516858/516858 [==============================] - 39s 75us/sample - loss: 0.1682 - accuracy: 0.9290 - val_loss: 0.1979 - val_accuracy: 0.9164 - lr: 1.0000e-04\n",
      "Epoch 60/73\n",
      "516858/516858 [==============================] - 39s 76us/sample - loss: 0.1681 - accuracy: 0.9291 - val_loss: 0.1993 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
      "Epoch 61/73\n",
      "516858/516858 [==============================] - 39s 75us/sample - loss: 0.1678 - accuracy: 0.9291 - val_loss: 0.2000 - val_accuracy: 0.9162 - lr: 1.0000e-04\n",
      "Epoch 62/73\n",
      "516858/516858 [==============================] - 39s 75us/sample - loss: 0.1677 - accuracy: 0.9293 - val_loss: 0.2013 - val_accuracy: 0.9169 - lr: 1.0000e-04\n",
      "Epoch 63/73\n",
      "516858/516858 [==============================] - 38s 74us/sample - loss: 0.1675 - accuracy: 0.9295 - val_loss: 0.1981 - val_accuracy: 0.9163 - lr: 1.0000e-04\n",
      "Epoch 64/73\n",
      "516858/516858 [==============================] - 36s 70us/sample - loss: 0.1673 - accuracy: 0.9293 - val_loss: 0.2026 - val_accuracy: 0.9158 - lr: 1.0000e-04\n",
      "Epoch 65/73\n",
      "516858/516858 [==============================] - 37s 71us/sample - loss: 0.1671 - accuracy: 0.9296 - val_loss: 0.1984 - val_accuracy: 0.9170 - lr: 1.0000e-04\n",
      "Epoch 66/73\n",
      "516858/516858 [==============================] - 37s 71us/sample - loss: 0.1671 - accuracy: 0.9296 - val_loss: 0.1983 - val_accuracy: 0.9171 - lr: 1.0000e-04\n",
      "Epoch 67/73\n",
      "516858/516858 [==============================] - 37s 72us/sample - loss: 0.1669 - accuracy: 0.9297 - val_loss: 0.1996 - val_accuracy: 0.9166 - lr: 1.0000e-04\n",
      "Epoch 68/73\n",
      "516858/516858 [==============================] - 38s 73us/sample - loss: 0.1667 - accuracy: 0.9295 - val_loss: 0.1983 - val_accuracy: 0.9169 - lr: 1.0000e-04\n",
      "Epoch 69/73\n",
      "516858/516858 [==============================] - 38s 74us/sample - loss: 0.1667 - accuracy: 0.9295 - val_loss: 0.1978 - val_accuracy: 0.9173 - lr: 1.0000e-04\n",
      "Epoch 70/73\n",
      "516858/516858 [==============================] - 38s 73us/sample - loss: 0.1635 - accuracy: 0.9307 - val_loss: 0.1952 - val_accuracy: 0.9185 - lr: 1.0000e-05\n",
      "Epoch 71/73\n",
      "516858/516858 [==============================] - 37s 72us/sample - loss: 0.1631 - accuracy: 0.9308 - val_loss: 0.1951 - val_accuracy: 0.9184 - lr: 1.0000e-05\n",
      "Epoch 72/73\n",
      "516858/516858 [==============================] - 39s 76us/sample - loss: 0.1631 - accuracy: 0.9311 - val_loss: 0.1950 - val_accuracy: 0.9183 - lr: 1.0000e-05\n",
      "Epoch 73/73\n",
      "516858/516858 [==============================] - 32s 61us/sample - loss: 0.1630 - accuracy: 0.9310 - val_loss: 0.1950 - val_accuracy: 0.9179 - lr: 1.0000e-05\n",
      "Training time: 2655.659632205963\n"
     ]
    }
   ],
   "source": [
    "# Training step with the best hyperparameters\n",
    "\n",
    "nadam = optimizers.Nadam(learning_rate = 0.01946960847019594, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08, schedule_decay = 0.004)\n",
    "\n",
    "model = CNN()\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"nadam\", metrics = [\"accuracy\"])\n",
    "\n",
    "train_start = time.time()\n",
    "\n",
    "history = model.fit(X_train_CNN, Y_train_CNN, \n",
    "                    epochs = int(73.1325893712185), \n",
    "                    batch_size = int(32 * 3.179494411695542), \n",
    "                    validation_data = (X_val_CNN, Y_val_CNN),\n",
    "                    callbacks = [reduce_lr])\n",
    "\n",
    "train_end = time.time()\n",
    "train_time = train_end - train_start\n",
    "print(\"Training time:\", train_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbc1826",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9a12f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andressa.amaral/.local/lib/python3.7/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing time: 4.851378440856934\n"
     ]
    }
   ],
   "source": [
    "# Testing step\n",
    "\n",
    "test_start = time.time()\n",
    "\n",
    "Y_pred = model.predict(X_test_CNN)\n",
    "\n",
    "test_end = time.time()\n",
    "test_time = test_end - test_start\n",
    "print(\"Testing time:\", test_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69b4a840",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_CNN = np.argmax(Y_pred, axis = 1)\n",
    "Y_true_CNN = Y_test_CNN.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97909195",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eebde8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Mirai_Ack','Mirai_Scan','Mirai_Syn','Mirai_Udp','Mirai_Udpplain',\n",
    "          'Bashlite_Combo','Bashlite_Junk','Bashlite_Scan','Bashlite_Udp', 'Bashlite_Tcp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0f94382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi classification metrics\n",
    "\n",
    "acc = accuracy_score(Y_true_CNN, Y_pred_CNN) \n",
    "f1 = f1_score(Y_true_CNN, Y_pred_CNN, average = 'weighted')\n",
    "pre = precision_score(Y_true_CNN, Y_pred_CNN, labels = None, pos_label = 1, average = 'weighted')\n",
    "recall = recall_score(Y_true_CNN, Y_pred_CNN, labels = None, pos_label = 1, average = 'weighted', sample_weight = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fd99081",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout = open(\"../Results/P838_camera_cnn.txt\", \"a\")\n",
    "\n",
    "print(\" ==== Test \" + str(number_features) + \" features \" + str(learning_rate) + \"====\")\n",
    "print(\"Training time:\" + str(train_time))\n",
    "print(\"Testing time:\" + str(test_time))\n",
    "print(\"Accuracy:\" + str(acc))\n",
    "print(\"F1-score:\" + str(f1))\n",
    "print(\"Precision:\" + str(pre))\n",
    "print(\"Recall:\" + str(recall))\n",
    "#print(\"Hyper-parameters:\" + str(optimizer.max))\n",
    "print(classification_report(Y_true_CNN,Y_pred_CNN, target_names = labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa80dcf5",
   "metadata": {},
   "source": [
    "## Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6446d067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Train\n",
    "train_nb_start = time.time()\n",
    "\n",
    "nb.fit(X_train, Y_train)\n",
    "\n",
    "train_nb_end = time.time()\n",
    "train_nb_time = train_nb_end - train_nb_start\n",
    "\n",
    "# Test\n",
    "test_nb_start = time.time()\n",
    "\n",
    "Y_pred_nb = nb.predict(X_test)\n",
    "\n",
    "test_nb_end = time.time()\n",
    "test_nb_time = test_nb_end - test_nb_start\n",
    "\n",
    "# Metrics\n",
    "acc_nb = accuracy_score(Y_test, Y_pred_nb) \n",
    "f1_nb = f1_score(Y_test, Y_pred_nb, average = 'weighted')\n",
    "pre_nb = precision_score(Y_test, Y_pred_nb, labels = None, pos_label = 1, average = 'weighted')\n",
    "recall_nb = recall_score(Y_test, Y_pred_nb, labels = None, pos_label = 1, average = 'weighted', sample_weight = None)\n",
    "\n",
    "print()\n",
    "print(\" ==== Naive Bayes \" + str(number_features) + \" features ====\")\n",
    "print(\"Training time:\" + str(train_nb_time))\n",
    "print(\"Testing time:\" + str(test_nb_time))\n",
    "print(\"Accuracy:\" + str(acc_nb))\n",
    "print(\"F1-score:\" + str(f1_nb))\n",
    "print(\"Precision:\" + str(pre_nb))\n",
    "print(\"Recall:\" + str(recall_nb))\n",
    "print(classification_report(Y_test,Y_pred_nb, target_names = labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b997f8f",
   "metadata": {},
   "source": [
    "## KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70d67978",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7622/214577653.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtest_knn_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mY_pred_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtest_knn_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mdata\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \"\"\"\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    757\u001b[0m                     \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m                     \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                     \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 )\n\u001b[1;32m    761\u001b[0m             )\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1715\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m         \u001b[0mD_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m         if (X is Y or Y is None) and PAIRWISE_DISTANCE_FUNCTIONS.get(\n\u001b[1;32m   1719\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1887\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1889\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    328\u001b[0m             )\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_euclidean_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_norm_squared\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_norm_squared\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_euclidean_distances\u001b[0;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;31m# if dtype is already float64, no need to chunk and upcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m         \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mYY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     if (\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model\n",
    "knn = KNeighborsClassifier(n_neighbors = 50)\n",
    "\n",
    "# Train\n",
    "train_knn_start = time.time()\n",
    "\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "train_knn_end = time.time()\n",
    "train_knn_time = train_knn_end - train_knn_start\n",
    "\n",
    "# Test\n",
    "test_knn_start = time.time()\n",
    "\n",
    "Y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "test_knn_end = time.time()\n",
    "test_knn_time = test_knn_end - test_knn_start\n",
    "\n",
    "# Metrics\n",
    "acc_knn = accuracy_score(Y_test, Y_pred_knn) \n",
    "f1_knn = f1_score(Y_test, Y_pred_knn, average = 'weighted')\n",
    "pre_knn = precision_score(Y_test, Y_pred_knn, labels = None, pos_label = 1, average = 'weighted')\n",
    "recall_knn = recall_score(Y_test, Y_pred_knn, labels = None, pos_label = 1, average = 'weighted', sample_weight = None)\n",
    "\n",
    "print()\n",
    "print(\" ==== KNN \" + str(number_features) + \" features ====\")\n",
    "print(\"Training time:\" + str(train_knn_time))\n",
    "print(\"Testing time:\" + str(test_knn_time))\n",
    "print(\"Accuracy:\" + str(acc_knn))\n",
    "print(\"F1-score:\" + str(f1_knn))\n",
    "print(\"Precision:\" + str(pre_knn))\n",
    "print(\"Recall:\" + str(recall_knn))\n",
    "print(classification_report(Y_test,Y_pred_knn, target_names = labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
