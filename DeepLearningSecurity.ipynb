{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91592d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/andressa.amaral/.local/lib/python3.6/site-packages (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/andressa.amaral/.local/lib/python3.6/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/andressa.amaral/.local/lib/python3.6/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.3->pandas) (1.11.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.layers import Lambda, Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Input, Dense, Lambda, Layer, Add, Multiply\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95097630",
   "metadata": {},
   "source": [
    "# Danmini_Doorbell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5116f65e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size:  (49548, 115)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MI_dir_L5_weight</th>\n",
       "      <th>MI_dir_L5_mean</th>\n",
       "      <th>MI_dir_L5_variance</th>\n",
       "      <th>MI_dir_L3_weight</th>\n",
       "      <th>MI_dir_L3_mean</th>\n",
       "      <th>MI_dir_L3_variance</th>\n",
       "      <th>MI_dir_L1_weight</th>\n",
       "      <th>MI_dir_L1_mean</th>\n",
       "      <th>MI_dir_L1_variance</th>\n",
       "      <th>MI_dir_L0.1_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>HpHp_L0.1_radius</th>\n",
       "      <th>HpHp_L0.1_covariance</th>\n",
       "      <th>HpHp_L0.1_pcc</th>\n",
       "      <th>HpHp_L0.01_weight</th>\n",
       "      <th>HpHp_L0.01_mean</th>\n",
       "      <th>HpHp_L0.01_std</th>\n",
       "      <th>HpHp_L0.01_magnitude</th>\n",
       "      <th>HpHp_L0.01_radius</th>\n",
       "      <th>HpHp_L0.01_covariance</th>\n",
       "      <th>HpHp_L0.01_pcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.409505e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.319895</td>\n",
       "      <td>344.262695</td>\n",
       "      <td>4.710446</td>\n",
       "      <td>344.262695</td>\n",
       "      <td>2.218830e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.857879</td>\n",
       "      <td>360.458980</td>\n",
       "      <td>3.578934e+01</td>\n",
       "      <td>1.912127</td>\n",
       "      <td>360.275733</td>\n",
       "      <td>3.592397e+01</td>\n",
       "      <td>1.969807</td>\n",
       "      <td>360.091968</td>\n",
       "      <td>35.991542</td>\n",
       "      <td>1.996939</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000815e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.318264</td>\n",
       "      <td>347.703087</td>\n",
       "      <td>9.034660</td>\n",
       "      <td>347.703087</td>\n",
       "      <td>8.162508e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.680223</td>\n",
       "      <td>172.140917</td>\n",
       "      <td>1.848745e+04</td>\n",
       "      <td>1.793580</td>\n",
       "      <td>182.560279</td>\n",
       "      <td>1.892818e+04</td>\n",
       "      <td>1.925828</td>\n",
       "      <td>193.165753</td>\n",
       "      <td>19153.795810</td>\n",
       "      <td>1.992323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49543</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>1.820000e-12</td>\n",
       "      <td>1.000009</td>\n",
       "      <td>101.999633</td>\n",
       "      <td>0.015405</td>\n",
       "      <td>2.270210</td>\n",
       "      <td>...</td>\n",
       "      <td>3.640000e-12</td>\n",
       "      <td>-1.570000e-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.218824</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>144.249783</td>\n",
       "      <td>1.820000e-12</td>\n",
       "      <td>5.970000e-23</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49544</th>\n",
       "      <td>1.999976</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.999986</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>1.820000e-12</td>\n",
       "      <td>2.000004</td>\n",
       "      <td>101.999816</td>\n",
       "      <td>0.007702</td>\n",
       "      <td>3.270209</td>\n",
       "      <td>...</td>\n",
       "      <td>3.640000e-12</td>\n",
       "      <td>-1.580000e-44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.218838</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>144.249783</td>\n",
       "      <td>3.640000e-12</td>\n",
       "      <td>-1.100000e-29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49545</th>\n",
       "      <td>2.999872</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>3.640000e-12</td>\n",
       "      <td>2.999923</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>1.820000e-12</td>\n",
       "      <td>2.999983</td>\n",
       "      <td>101.999878</td>\n",
       "      <td>0.005135</td>\n",
       "      <td>4.270206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-8.330000e-45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.179949</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>144.249783</td>\n",
       "      <td>5.140000e-12</td>\n",
       "      <td>8.230000e-29</td>\n",
       "      <td>2.260000e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49546</th>\n",
       "      <td>3.999664</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>3.640000e-12</td>\n",
       "      <td>3.999798</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.999942</td>\n",
       "      <td>101.999908</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>5.270200</td>\n",
       "      <td>...</td>\n",
       "      <td>3.640000e-12</td>\n",
       "      <td>4.980000e-69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.219537</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>144.249783</td>\n",
       "      <td>1.820000e-12</td>\n",
       "      <td>5.960000e-29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49547</th>\n",
       "      <td>4.997694</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>3.640000e-12</td>\n",
       "      <td>4.998617</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>1.820000e-12</td>\n",
       "      <td>4.999548</td>\n",
       "      <td>101.999927</td>\n",
       "      <td>0.003081</td>\n",
       "      <td>6.270148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.450000e-39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.219212</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>144.249783</td>\n",
       "      <td>2.570000e-12</td>\n",
       "      <td>2.920000e-26</td>\n",
       "      <td>1.600000e-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49548 rows Ã— 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MI_dir_L5_weight  MI_dir_L5_mean  MI_dir_L5_variance  MI_dir_L3_weight  \\\n",
       "0              1.000000       60.000000        0.000000e+00          1.000000   \n",
       "1              1.000000      354.000000        0.000000e+00          1.000000   \n",
       "2              1.857879      360.458980        3.578934e+01          1.912127   \n",
       "3              1.000000      337.000000        0.000000e+00          1.000000   \n",
       "4              1.680223      172.140917        1.848745e+04          1.793580   \n",
       "...                 ...             ...                 ...               ...   \n",
       "49543          1.000000      102.000000        0.000000e+00          1.000000   \n",
       "49544          1.999976      102.000000        0.000000e+00          1.999986   \n",
       "49545          2.999872      102.000000        3.640000e-12          2.999923   \n",
       "49546          3.999664      102.000000        3.640000e-12          3.999798   \n",
       "49547          4.997694      102.000000        3.640000e-12          4.998617   \n",
       "\n",
       "       MI_dir_L3_mean  MI_dir_L3_variance  MI_dir_L1_weight  MI_dir_L1_mean  \\\n",
       "0           60.000000        0.000000e+00          1.000000       60.000000   \n",
       "1          354.000000        0.000000e+00          1.000000      354.000000   \n",
       "2          360.275733        3.592397e+01          1.969807      360.091968   \n",
       "3          337.000000        0.000000e+00          1.000000      337.000000   \n",
       "4          182.560279        1.892818e+04          1.925828      193.165753   \n",
       "...               ...                 ...               ...             ...   \n",
       "49543      102.000000        1.820000e-12          1.000009      101.999633   \n",
       "49544      102.000000        1.820000e-12          2.000004      101.999816   \n",
       "49545      102.000000        1.820000e-12          2.999983      101.999878   \n",
       "49546      102.000000        0.000000e+00          3.999942      101.999908   \n",
       "49547      102.000000        1.820000e-12          4.999548      101.999927   \n",
       "\n",
       "       MI_dir_L1_variance  MI_dir_L0.1_weight  ...  HpHp_L0.1_radius  \\\n",
       "0                0.000000            1.000000  ...      0.000000e+00   \n",
       "1                0.000000            1.000000  ...      3.409505e+01   \n",
       "2               35.991542            1.996939  ...      1.000815e+02   \n",
       "3                0.000000            1.000000  ...      0.000000e+00   \n",
       "4            19153.795810            1.992323  ...      0.000000e+00   \n",
       "...                   ...                 ...  ...               ...   \n",
       "49543            0.015405            2.270210  ...      3.640000e-12   \n",
       "49544            0.007702            3.270209  ...      3.640000e-12   \n",
       "49545            0.005135            4.270206  ...      0.000000e+00   \n",
       "49546            0.003851            5.270200  ...      3.640000e-12   \n",
       "49547            0.003081            6.270148  ...      0.000000e+00   \n",
       "\n",
       "       HpHp_L0.1_covariance  HpHp_L0.1_pcc  HpHp_L0.01_weight  \\\n",
       "0              0.000000e+00            0.0           1.000000   \n",
       "1              0.000000e+00            0.0           5.319895   \n",
       "2              0.000000e+00            0.0           6.318264   \n",
       "3              0.000000e+00            0.0           1.000000   \n",
       "4              0.000000e+00            0.0           1.000000   \n",
       "...                     ...            ...                ...   \n",
       "49543         -1.570000e-30            0.0           4.218824   \n",
       "49544         -1.580000e-44            0.0           4.218838   \n",
       "49545         -8.330000e-45            0.0           4.179949   \n",
       "49546          4.980000e-69            0.0           4.219537   \n",
       "49547          7.450000e-39            0.0           4.219212   \n",
       "\n",
       "       HpHp_L0.01_mean  HpHp_L0.01_std  HpHp_L0.01_magnitude  \\\n",
       "0            60.000000        0.000000             60.000000   \n",
       "1           344.262695        4.710446            344.262695   \n",
       "2           347.703087        9.034660            347.703087   \n",
       "3           337.000000        0.000000            337.000000   \n",
       "4            60.000000        0.000000             60.000000   \n",
       "...                ...             ...                   ...   \n",
       "49543       102.000000        0.000000            144.249783   \n",
       "49544       102.000000        0.000000            144.249783   \n",
       "49545       102.000000        0.000002            144.249783   \n",
       "49546       102.000000        0.000001            144.249783   \n",
       "49547       102.000000        0.000001            144.249783   \n",
       "\n",
       "       HpHp_L0.01_radius  HpHp_L0.01_covariance  HpHp_L0.01_pcc  \n",
       "0           0.000000e+00           0.000000e+00    0.000000e+00  \n",
       "1           2.218830e+01           0.000000e+00    0.000000e+00  \n",
       "2           8.162508e+01           0.000000e+00    0.000000e+00  \n",
       "3           0.000000e+00           0.000000e+00    0.000000e+00  \n",
       "4           0.000000e+00           0.000000e+00    0.000000e+00  \n",
       "...                  ...                    ...             ...  \n",
       "49543       1.820000e-12           5.970000e-23    0.000000e+00  \n",
       "49544       3.640000e-12          -1.100000e-29    0.000000e+00  \n",
       "49545       5.140000e-12           8.230000e-29    2.260000e-17  \n",
       "49546       1.820000e-12           5.960000e-29    0.000000e+00  \n",
       "49547       2.570000e-12           2.920000e-26    1.600000e-14  \n",
       "\n",
       "[49548 rows x 115 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Benign traffic\n",
    "dataframe_dd_benign = pd.read_csv('nbaiot/Danmini_Doorbell/benign_traffic.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_dd_benign = dataframe_dd_benign.copy(deep=True)\n",
    "\n",
    "print(\"Size: \", df_dd_benign.shape); \n",
    "display(df_dd_benign.head(49548))\n",
    "\n",
    "# Mirai\n",
    "dataframe_dd_mirai_ack = pd.read_csv('nbaiot/Danmini_Doorbell/mirai/ack.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_dd_mirai_ack = dataframe_dd_mirai_ack.copy(deep=True)\n",
    "\n",
    "dataframe_dd_mirai_scan = pd.read_csv('nbaiot/Danmini_Doorbell/mirai/scan.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_dd_mirai_scan = dataframe_dd_mirai_scan.copy(deep=True)\n",
    "\n",
    "dataframe_dd_mirai_syn = pd.read_csv('nbaiot/Danmini_Doorbell/mirai/syn.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_dd_mirai_syn = dataframe_dd_mirai_syn.copy(deep=True)\n",
    "\n",
    "dataframe_dd_mirai_udp = pd.read_csv('nbaiot/Danmini_Doorbell/mirai/udp.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_dd_mirai_udp = dataframe_dd_mirai_udp.copy(deep=True)\n",
    "\n",
    "dataframe_dd_mirai_udpplain = pd.read_csv('nbaiot/Danmini_Doorbell/mirai/udpplain.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_dd_mirai_udpplain = dataframe_dd_mirai_udpplain.copy(deep=True)\n",
    "\n",
    "# Gafgyt\n",
    "dataframe_dd_gafgyt_combo = pd.read_csv('nbaiot/Danmini_Doorbell/gafgyt/combo.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_dd_gafgyt_combo = dataframe_dd_gafgyt_combo.copy(deep=True)\n",
    "\n",
    "dataframe_dd_gafgyt_junk = pd.read_csv('nbaiot/Danmini_Doorbell/gafgyt/junk.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_dd_gafgyt_gafgyt = dataframe_dd_gafgyt_junk.copy(deep=True)\n",
    "\n",
    "dataframe_dd_gafgyt_scan = pd.read_csv('nbaiot/Danmini_Doorbell/gafgyt/scan.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_dd_gafgyt_scan = dataframe_dd_gafgyt_scan.copy(deep=True)\n",
    "\n",
    "dataframe_dd_gafgyt_udp = pd.read_csv('nbaiot/Danmini_Doorbell/gafgyt/udp.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_dd_gafgyt_udp = dataframe_dd_gafgyt_udp.copy(deep=True)\n",
    "\n",
    "dataframe_dd_gafgyt_tcp = pd.read_csv('nbaiot/Danmini_Doorbell/gafgyt/tcp.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_dd_gafgyt_tcp = dataframe_dd_gafgyt_udp.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5b4119",
   "metadata": {},
   "source": [
    "# Variational Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5756e525",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df_dd_benign_norm = scaler.fit_transform(df_dd_benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34ee3063",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dim = df_dd_benign.shape[1]-1\n",
    "input_shape = (original_dim, )\n",
    "intermediate_dim = int(original_dim/2)\n",
    "batch_size = 64\n",
    "latent_dim = 64\n",
    "epochs = 10\n",
    "epsilon_std = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22b2260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KLDivergenceLayer(Layer):\n",
    "\n",
    "    #Identity transform layer that adds KL divergence\n",
    "    #to the final model loss.\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(KLDivergenceLayer, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        mu, log_var = inputs\n",
    "        kl_batch = - .5 * K.sum(1 + log_var - K.square(mu) - K.exp(log_var), axis=-1)\n",
    "        self.add_loss(K.mean(kl_batch), inputs=inputs)\n",
    "\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d54a5808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_model(original_dim, intermediate_dim, latent_dim):\n",
    "    # Decode \n",
    "    decoder = Sequential([\n",
    "                Dense(intermediate_dim, input_dim=latent_dim, activation='relu'),\n",
    "                Dense(original_dim, activation='sigmoid')\n",
    "            ])\n",
    "\n",
    "    # Encode\n",
    "    x = Input(shape=(original_dim,))\n",
    "    h = Dense(intermediate_dim, activation='relu')(x)\n",
    "\n",
    "    z_mu = Dense(latent_dim)(h)\n",
    "    z_log_var = Dense(latent_dim)(h)\n",
    "\n",
    "    z_mu, z_log_var = KLDivergenceLayer()([z_mu, z_log_var])\n",
    "    z_sigma = Lambda(lambda t: K.exp(.5*t))(z_log_var)\n",
    "\n",
    "    eps = Input(tensor=K.random_normal(stddev=epsilon_std, shape=(K.shape(x)[0], latent_dim)))\n",
    "\n",
    "    z_eps = Multiply()([z_sigma, eps])\n",
    "    z = Add()([z_mu, z_eps])\n",
    "\n",
    "    x_pred = decoder(z)\n",
    "    \n",
    "    return x, eps, z_mu, x_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42a8f552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(y_true, y_pred):\n",
    "    # Negative log likelihood (Bernoulli)\n",
    "    # Keras.losses.binary_crossentropy gives the mean\n",
    "    # Over the last axis. We require the sum\n",
    "    \n",
    "    return K.sum(K.binary_crossentropy(y_true, y_pred), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80d0d5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1221 21:27:13.253366 140543285155648 deprecation.py:506] From /usr/lib/python3/dist-packages/keras/backend/tensorflow_backend.py:1242: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "W1221 21:27:13.309286 140543285155648 deprecation_wrapper.py:119] From /usr/lib/python3/dist-packages/keras/backend/tensorflow_backend.py:3607: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W1221 21:27:13.323821 140543285155648 deprecation_wrapper.py:119] From /usr/lib/python3/dist-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1221 21:27:13.427416 140543285155648 deprecation_wrapper.py:119] From /usr/lib/python3/dist-packages/keras/backend/tensorflow_backend.py:2944: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1221 21:27:13.431342 140543285155648 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "x, eps, z_mu, x_pred = vae_model(original_dim, intermediate_dim, latent_dim)\n",
    "vae = Model(inputs = [x, eps], outputs = x_pred)\n",
    "vae.compile(optimizer = 'adam', loss = nll)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d08767e",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7fbd2ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df_dd_benign_norm, df_dd_benign_norm, test_size = 0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ba69f57",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_1 to have shape (None, 114) but got array with shape (34683, 115)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-15ecc1c67eb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0;31m#callbacks = callbacks_list,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                 validation_data = (X_test, X_test))\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1572\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1574\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1575\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1405\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1408\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1409\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    151\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_1 to have shape (None, 114) but got array with shape (34683, 115)"
     ]
    }
   ],
   "source": [
    "hist = vae.fit(X_train, X_train,\n",
    "                epochs = epochs,\n",
    "                batch_size = batch_size,\n",
    "                #callbacks = callbacks_list,\n",
    "                validation_data = (X_test, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af0958c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
